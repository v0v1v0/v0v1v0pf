<div class="container">

<table style="width: 100%;"><tr>
<td>hash.size</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute minimum hash size to reduce collision rate</h2>

<h3>Description</h3>

<p>Compute minimum hash size to reduce collision rate
</p>


<h3>Usage</h3>

<pre><code class="language-R">hash.size(df)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p><code>data.frame</code> with data to hash</p>
</td>
</tr></table>
<h3>Details</h3>

<p>To reduce collision rate, the hash size should be 
equal or superior to the nearest power of two to the number
of unique values in the input <code>data.frame</code>.
</p>
<p>The value computed is a theorical minimum hash size.
It just means that in the best situation it may be 
possible that all computed hash can be stored with
this hash size.
</p>
<p>Intuitively, if the distribution of hash generated by the algorithm
was perfect, when the computed size is used, each permutation of bits
of the hash vector would correspond to one unique original value of
your <code>data.frame</code>. 
</p>
<p>Because a bit value is <code>{0,1}</code>, the computed size is <code>2^x</code>
with a <code>x</code> big enough to have a hash vector containing each
original value.
</p>
<p>In real life, there will be some collisions if the computed
size is used because the distribution of hash is not
perfect. However, the hashing algorithm <code>Murmur3</code> is known to
minimize the number of collisions and is also very performant.
</p>
<p>The only known solution to have zero collision is to build a
dictionnary of values, and for each new value to hash, check in the
dictionnary if the hash value already exists. It is not performant at all.
</p>
<p>If you increase the computed size (by multiplying it by <code>2^x</code>, 
it is up to you to choose a <code>x</code>), you will reduce the collision rate.
If you use a value under the computed size,
there is a 100
</p>
<p>There is a trade-off between collision rate and memory
used to store hash. Machine learning algorithms usually deal
well with collisions when the rate is reasonable.
</p>


<h3>Value</h3>

<p>The hash size of feature hashing as a positive integer.
</p>


<h3>Author(s)</h3>

<p>Michael Benesty
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(ipinyou)

#First try with a size of 2^10
mat1 &lt;- hashed.model.matrix(~., ipinyou.train, 2^10, create.mapping = TRUE)

#Extract mapping
mapping1 &lt;- hash.mapping(mat1)
#Rate of collision
mean(duplicated(mapping1))

#Second try, the size is computed
size &lt;- hash.size(ipinyou.train)
mat2 &lt;- hashed.model.matrix(~., ipinyou.train, size, create.mapping = TRUE)

#Extract mapping
mapping2 &lt;- hash.mapping(mat2)
#Rate of collision
mean(duplicated(mapping2))

</code></pre>


</div>