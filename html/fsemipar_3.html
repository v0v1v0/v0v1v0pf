<div class="container">

<table style="width: 100%;"><tr>
<td>FASSMR.kNN.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Impact point selection with FASSMR and kNN estimation
</h2>

<h3>Description</h3>

<p>This function implements the Fast Algorithm for Sparse Semiparametric Multi-functional Regression (FASSMR) with kNN estimation. This algorithm is specifically designed for estimating multi-functional partial linear single-index models, which incorporate multiple scalar variables and a functional covariate as predictors. These scalar variables are derived from the discretisation of a curve and have linear effect while the functional covariate exhibits a single-index effect. 
</p>
<p>FASSMR selects the impact points of the discretised curve and estimates the model. The algorithm employs a penalised least-squares regularisation procedure, integrated with kNN estimation using Nadaraya-Watson weights. It uses B-spline expansions to represent curves and eligible functional indexes. Additionally, it utilises an objective criterion (<code>criterion</code>) to determine the initial number of covariates in the reduced model (<code>w.opt</code>), the number of neighbours (<code>k.opt</code>), and the penalisation parameter (<code>lambda.opt</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">FASSMR.kNN.fit(x, z, y, seed.coeff = c(-1, 0, 1), order.Bspline = 3, 
nknot.theta = 3,  knearest = NULL, min.knn = 2, max.knn = NULL, step = NULL,  
kind.of.kernel = "quad",range.grid = NULL, nknot = NULL, lambda.min = NULL, 
lambda.min.h = NULL, lambda.min.l = NULL, factor.pn = 1, nlambda = 100, 
vn = ncol(z), nfolds = 10, seed = 123, wn = c(10, 15, 20), criterion = "GCV", 
penalty = "grSCAD", max.iter = 1000, n.core = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Matrix containing the observations of the functional covariate collected by row (functional single-index component).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>

<p>Matrix containing the observations of the functional covariate that is discretised collected by row (linear component).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Vector containing the scalar response.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed.coeff</code></td>
<td>

<p>Vector of initial values used to  build the set <code class="reqn">\Theta_n</code> (see section <code>Details</code>). The coefficients for the B-spline representation of each eligible functional index <code class="reqn">\theta \in \Theta_n</code> are obtained from <code>seed.coeff</code>.  The default is <code>c(-1,0,1)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order.Bspline</code></td>
<td>

<p>Positive integer giving the order of the B-spline basis functions. This is the number of coefficients in each piecewise polynomial segment. The default is 3.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nknot.theta</code></td>
<td>

<p>Positive integer indicating the number of regularly spaced interior knots in the B-spline expansion of <code class="reqn">\theta_0</code>. The default is 3.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knearest</code></td>
<td>

<p>Vector of positive integers containing the sequence in which the  number of nearest neighbours <code>k.opt</code> is selected. If <code>knearest=NULL</code>, then <code>knearest &lt;- seq(from =min.knn, to = max.knn, by = step)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.knn</code></td>
<td>

<p>A positive integer that represents the minimum value in the sequence for selecting the number of nearest neighbours <code>k.opt</code>. This value should be less than the sample size. The default is 2.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.knn</code></td>
<td>

<p>A positive integer that represents the maximum value in the sequence for selecting number of nearest neighbours <code>k.opt</code>. This value should be less than the sample size. The default is <code>max.knn &lt;- n%/%5</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>

<p>A positive integer used to construct the sequence of k-nearest neighbours as follows: <code>min.knn, min.knn + step, min.knn + 2*step, min.knn + 3*step,...</code>. The default value for <code>step</code> is <code>step&lt;-ceiling(n/100)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kind.of.kernel</code></td>
<td>

<p>The type of kernel function used. Currently, only Epanechnikov kernel (<code>"quad"</code>) is available.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>range.grid</code></td>
<td>

<p>Vector of length 2 containing the endpoints of the grid at which the observations of the functional covariate <code>x</code> are evaluated (i.e. the range of the discretisation). If <code>range.grid=NULL</code>, then <code>range.grid=c(1,p)</code> is considered, where <code>p</code> is the discretisation size of <code>x</code> (i.e. <code>ncol(x))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nknot</code></td>
<td>

<p>Positive integer indicating the number of interior knots for the B-spline expansion of the functional covariate. The default value is <code>(p - order.Bspline - 1)%/%2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>

<p>The smallest value for lambda (i. e., the lower endpoint  of the sequence in which <code>lambda.opt</code> is selected), as fraction of <code>lambda.max</code>.
The defaults is <code>lambda.min.l</code> if the sample size is larger than <code>factor.pn</code> times the number of linear covariates and <code>lambda.min.h</code> otherwise.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.h</code></td>
<td>

<p>The lower endpoint of the sequence in which <code>lambda.opt</code> is selected if the sample size is smaller than <code>factor.pn</code> times the number of linear covariates. The default is 0.05. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.l</code></td>
<td>

<p>The lower endpoint of the sequence in which <code>lambda.opt</code> is selected if the sample size is larger than <code>factor.pn</code> times the number of linear covariates. The default is 0.0001.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor.pn</code></td>
<td>

<p>Positive integer used to set <code>lambda.min</code>. The default value is 1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>

<p>Positive integer indicating the number of values in the sequence from which <code>lambda.opt</code> is selected. The default is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vn</code></td>
<td>

<p>Positive integer or vector of positive integers indicating the number of groups of consecutive variables to be penalised together. The default value is <code>vn=ncol(z)</code>, resulting in the individual penalization of each scalar covariate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>

<p>Positive integer indicating the number of cross-validation folds (used when <code>criterion="k-fold-CV"</code>). Default is 10.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>You may set the seed for the random number generator to ensure reproducible results (applicable when <code>criterion="k-fold-CV"</code> is used). The default seed value is 123.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wn</code></td>
<td>

<p>A vector of positive integers indicating the eligible number of covariates in the reduced model. For more information, refer to the section <code>Details</code>. The default is <code>c(10,15,20)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>

<p>The criterion used to select the tuning and regularisation parameters: <code>wn.opt</code>, <code>k.opt</code> and <code>lambda.opt</code> (also <code>vn.opt</code> if needed). Options include <code>"GCV"</code>, <code>"BIC"</code>, <code>"AIC"</code>, or <code>"k-fold-CV"</code>. The default setting is <code>"GCV"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>

<p>The penalty function applied in the penalised least-squares procedure. Currently, only "grLasso" and "grSCAD" are implemented. The default is "grSCAD".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>

<p>Maximum number of iterations allowed across the entire path. The default value is 1000.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.core</code></td>
<td>

<p>Number of CPU cores designated for parallel execution. The default is <code>n.core&lt;-availableCores(omit=1)</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The multi-functional partial linear single-index model (MFPLSIM) is given by the expression
</p>
<p style="text-align: center;"><code class="reqn">Y_i=\sum_{j=1}^{p_n}\beta_{0j}\zeta_i(t_j)+r\left(\left&lt;\theta_0,X_i\right&gt;\right)+\varepsilon_i,\ \ \ (i=1,\dots,n),</code>
</p>

<p>where: 
</p>

<ul>
<li> <p><code class="reqn">Y_i</code> is a real random response and <code class="reqn">X_i</code> denotes a random element belonging to some separable Hilbert space <code class="reqn">\mathcal{H}</code> with inner product denoted by <code class="reqn">\left\langle\cdot,\cdot\right\rangle</code>. The second functional predictor <code class="reqn">\zeta_i</code> is assumed to be a curve defined on some interval <code class="reqn">[a,b]</code> which  is observed at the points <code class="reqn">a\leq t_1&lt;\dots&lt;t_{p_n}\leq b</code>. 
</p>
</li>
<li>  <p><code class="reqn">\mathbf{\beta}_0=(\beta_{01},\dots,\beta_{0p_n})^{\top}</code> is a vector of unknown real coefficients and <code class="reqn">r(\cdot)</code> denotes a smooth unknown link function. In addition, <code class="reqn">\theta_0</code> is an unknown functional direction in <code class="reqn">\mathcal{H}</code>.  
</p>
</li>
<li> <p><code class="reqn">\varepsilon_i</code> denotes the random error.
</p>
</li>
</ul>
<p>In  the MFPLSIM, we assume that only a few scalar variables from the set <code class="reqn">\{\zeta(t_1),\dots,\zeta(t_{p_n})\}</code> form part of the model. Therefore, we must select the relevant variables in the linear component (the impact points of the curve <code class="reqn">\zeta</code> on the response) and estimate the model.
</p>
<p>In this function, the MFPLSIM is fitted using the FASSMR algorithm.  The main idea of this algorithm is to consider a reduced model, with only some (very few) linear covariates (but covering the entire discretization interval of <code class="reqn">\zeta</code>), and discarding directly the other linear covariates (since it is expected that they contain very similar information about the response). 
</p>
<p>To explain the algorithm, we assume, without loss of generality, that the number <code class="reqn">p_n</code> of linear covariates can be expressed as follows: <code class="reqn">p_n=q_nw_n</code> with <code class="reqn">q_n</code> and <code class="reqn">w_n</code> integers. 
This consideration allows us to build a subset of the initial <code class="reqn">p_n</code> linear covariates, containging only <code class="reqn">w_n</code> equally spaced discretised observations of  <code class="reqn">\zeta</code> covering the entire interval  <code class="reqn">[a,b]</code>. This subset is the following:
</p>
<p style="text-align: center;"><code class="reqn">
	\mathcal{R}_n^{\mathbf{1}}=\left\{\zeta\left(t_k^{\mathbf{1}}\right),\ \ k=1,\dots,w_n\right\},
</code>
</p>
 
<p>where  <code class="reqn">t_k^{\mathbf{1}}=t_{\left[(2k-1)q_n/2\right]}</code> and  <code class="reqn">\left[z\right]</code> denotes the smallest integer not less than the real number <code class="reqn">z</code>.
</p>
<p>We consider the following reduced model, which involves only the linear covariates belonging to <code class="reqn">\mathcal{R}_n^{\mathbf{1}}</code>:
</p>
<p style="text-align: center;"><code class="reqn">
	Y_i=\sum_{k=1}^{w_n}\beta_{0k}^{\mathbf{1}}\zeta_i(t_k^{\mathbf{1}})+r^{\mathbf{1}}\left(\left&lt;\theta_0^{\mathbf{1}},\mathcal{X}_i\right&gt;\right)+\varepsilon_i^{\mathbf{1}}.
</code>
</p>

<p>The program receives the eligible numbers of linear covariates for building the reduced model through the argument <code>wn</code>.
Then, the penalised least-squares variable selection procedure, with kNN estimation, is applied to the reduced model. This is done using the function <code>sfplsim.kNN.fit</code>, which requires the remaining arguments (for details, see the documentation of the function <code>sfplsim.kNN.fit</code>). The estimates obtained are the outputs of the FASSMR algorithm. For further details on this algorithm, see Novo et al. (2021).
</p>
<p><b>Remark</b>: If the condition  <code class="reqn">p_n=w_n q_n</code> is not met (then <code class="reqn">p_n/w_n</code> is not an integer number), the function considers variable  <code class="reqn">q_n=q_{n,k}</code> values <code class="reqn">k=1,\dots,w_n</code>. Specifically:
</p>
<p style="text-align: center;"><code class="reqn">
	q_{n,k}= \left\{\begin{array}{ll}
	[p_n/w_n]+1 &amp;   k\in\{1,\dots,p_n-w_n[p_n/w_n]\},\\
	{[p_n/w_n]} &amp; k\in\{p_n-w_n[p_n/w_n]+1,\dots,w_n\},
	\end{array}
	\right.
</code>
</p>

<p>where <code class="reqn">[z]</code> denotes the integer part of the real number <code class="reqn">z</code>.
</p>
<p>The function supports parallel computation. To avoid it, we can set <code>n.core=1</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>Estimated scalar response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>Differences between <code>y</code> and the <code>fitted.values</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.est</code></td>
<td>
<p><code class="reqn">\hat{\mathbf{\beta}}</code> (i.e. estimate of <code class="reqn">\mathbf{\beta}_0</code> when the optimal tuning parameters <code>w.opt</code>, <code>lambda.opt</code>, <code>k.opt</code> and <code>vn.opt</code> are used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.red</code></td>
<td>
<p>Estimate of <code class="reqn">\beta_0^{\mathbf{1}}</code> in the reduced model when the optimal tuning parameters <code>w.opt</code>, <code>lambda.opt</code>, <code>k.opt</code> and <code>vn.opt</code> are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.est</code></td>
<td>
<p>Coefficients of <code class="reqn">\hat{\theta}</code> in the B-spline basis (i.e. estimate of <code class="reqn">\theta_0</code> when the optimal tuning parameters <code>w.opt</code>, <code>lambda.opt</code>, <code>k.opt</code> and <code>vn.opt</code> are used): a vector of <code>length(order.Bspline+nknot.theta)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indexes.beta.nonnull</code></td>
<td>
<p>Indexes of the non-zero <code class="reqn">\hat{\beta_{j}}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k.opt</code></td>
<td>
<p>Selected number of nearest neighbours (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.opt</code></td>
<td>
<p>Selected size for  <code class="reqn">\mathcal{R}_n^{\mathbf{1}}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.opt</code></td>
<td>
<p>Selected value for the penalisation parameter (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>IC</code></td>
<td>
<p>Value of the criterion function considered to select <code>w.opt</code>, <code>lambda.opt</code>, <code>k.opt</code> and <code>vn.opt</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vn.opt</code></td>
<td>
<p>Selected value of <code>vn</code> (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.w</code></td>
<td>
<p>Estimate of <code class="reqn">\beta_0^{\mathbf{1}}</code> for each value of the sequence <code>wn</code> (i.e. for each number of covariates in the reduced model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.w</code></td>
<td>
<p>Estimate of <code class="reqn">\theta_0^{\mathbf{1}}</code> for each value of the sequence <code>wn</code> (i.e. its coefficients in the B-spline basis).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>IC.w</code></td>
<td>
<p>Value of the criterion function for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indexes.beta.nonnull.w</code></td>
<td>
<p>Indexes of the non-zero linear coefficients for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.w</code></td>
<td>
<p>Selected value of penalisation parameter for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k.w</code></td>
<td>
<p>Selected number of neighbours for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index01</code></td>
<td>
<p>Indexes of the covariates (in the entire set of <code class="reqn">p_n</code>) used to build  <code class="reqn">\mathcal{R}_n^{\mathbf{1}}</code> for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>German Aneiros Perez <a href="mailto:german.aneiros@udc.es">german.aneiros@udc.es</a> 
</p>
<p>Silvia Novo Diaz  <a href="mailto:snovo@est-econ.uc3m.es">snovo@est-econ.uc3m.es</a>
</p>


<h3>References</h3>

<p>Novo, S., Vieu, P., and Aneiros, G., (2021) Fast and efficient algorithms for
sparse semiparametric bi-functional regression. <em>Australian and New Zealand
Journal of Statistics</em>, <b>63</b>, 606–638, <a href="https://doi.org/10.1111/anzs.12355">doi:10.1111/anzs.12355</a>.
</p>


<h3>See Also</h3>

<p>See also <code>sfplsim.kNN.fit, predict.FASSMR.kNN</code>, <code>plot.FASSMR.kNN</code> and <code>IASSMR.kNN.fit</code>.
</p>
<p>Alternative method <code>FASSMR.kernel.fit</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Sugar)


y&lt;-Sugar$ash
x&lt;-Sugar$wave.290
z&lt;-Sugar$wave.240

#Outliers
index.y.25 &lt;- y &gt; 25
index.atip &lt;- index.y.25
(1:268)[index.atip]


#Dataset to model
x.sug &lt;- x[!index.atip,]
z.sug&lt;- z[!index.atip,]
y.sug &lt;- y[!index.atip]

train&lt;-1:216
ptm=proc.time()
fit&lt;- FASSMR.kNN.fit(x=x.sug[train,],z=z.sug[train,], y=y.sug[train], 
        nknot.theta=2, lambda.min.l=0.03, max.knn=20,nknot=20,criterion="BIC",
        max.iter=5000)
proc.time()-ptm

fit
names(fit)

  
</code></pre>


</div>