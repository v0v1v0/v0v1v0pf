<div class="container">

<table style="width: 100%;"><tr>
<td>fusionbinary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fusion learning algorithm for binary responses
</h2>

<h3>Description</h3>

<p><code>fusionbinary</code> conducts the group penalization with a specified penalty value learning from multiple generalized linear models with binary responses. <code>fusionbinary.fit</code> can be used to search the best candidate model based on the pseudo Bayesian information criterion with a sequence of penalty values.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fusionbinary(x, y, lambda, N, p, m, beta=0.1, thresh=0.1, 
             maxiter=100, methods="scad", link="logit", Complete=TRUE)

fusionbinary.fit(x, y, lambda, N, p, m, beta=0.1, thresh=0.1, 
                 maxiter=100, methods="scad", link="logit", Complete=TRUE, 
                 depen ="IND", a=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>List. Listing matrices of the predictors from different platforms. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>List. A list of binary responses vectors from different platforms following the same order as in <code>x</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>Numeric or vector. For <code>fusionbinary</code>, lambda is a numeric value for the penalty; for <code>fusionbinary.fit</code>, lambda is a vector with a list of penalty values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>

<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each data set. If a vector is provided, then the elements are the sample sizes for all the platforms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>

<p>Numeric. The number of predictors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>

<p>Numeric. The number of platforms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>

<p>Numeric. An initial value for the estimated parameters with dimensions nvars x nplatforms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thresh</code></td>
<td>

<p>Numeric. The stopping criteria. The default value is 0.1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>

<p>Numeric. Maximum number of iterations. The default value is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>methods</code></td>
<td>

<p>Character ("lass" or "scad"). <code>lass</code>: LASSO; <code>scad</code>: SCAD.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>link</code></td>
<td>

<p>Character ("logit" or "probit"). Link functions: logistic or probit.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Complete</code></td>
<td>

<p>Logic input. If <code>Complete == TRUE</code>, the predictors <code class="reqn">M_1</code>,...,<code class="reqn">M_p</code> are measured in all platforms. If <code>Compelte == FALSE</code>, in some platforms, not all of the predictors <code class="reqn">\{M_1,M_2,...,M_p\}</code> are measured. The values of the corresponding estimated coefficients for the missing predictors will be <code>NA</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>depen</code></td>
<td>

<p>Character. Input only for function <code>fusionbinary.fit</code>. "IND" means the observations across different platforms are independent; "CORR" means the observations are correlated, and the sample sizes should be equal for different platforms. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>

<p>Numeric. Input only for function <code>fusionbinary.fit</code>. The free multiplicative constant used in <code class="reqn">\gamma_n</code>. The default value is 1.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The generalized fusion learning function to learn from multiple models with binary responses. More details regarding the algorithm can be found in <code>FusionLearn</code>.
</p>


<h3>Value</h3>

<p><code>fusionbinary</code> returns a list that has components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>

<p>A matrix (nvars x nplatforms) containing estimated coefficients of each linear model. If some data sets do not have the complete set of predictors, the corresponding coefficients are output as <code>NA</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>Penalty function LASSO or SCAD.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>link</code></td>
<td>

<p>The link function used in the estimation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>

<p>The numeric value shows the difference in the estimates between the successive updates upon convergence. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iteration</code></td>
<td>

<p>The numeric value shows the number of iterations upon convergence.
</p>
</td>
</tr>
</table>
<p><code>fusionbinary.fit</code> provides the results in a table:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>The sequence of penalty values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BIC</code></td>
<td>

<p>The pseudolikelihood Bayesian information criterion evaluated at the sequence of the penalty values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>-2Loglkh</code></td>
<td>

<p>Minus twice the pseudo loglikelihood of the chosen model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Est_df</code></td>
<td>

<p>The estimated degrees of freedom quantifying the model complexity.
</p>
</td>
</tr>
</table>
<p><code>fusionbinary.fit</code> also returns a model selection plot showing the results above. 
</p>


<h3>Note</h3>

<p>The range of the penalty values should be carefully chosen. For some penalty values, the resulting models may have singular information matrix or the fitting of the glm cannot converge.
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong, and Raymond J. Carroll
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>Examples</h3>

<pre><code class="language-R">##Analysis of the gene data 
y = list(mockgene1[,2],mockgene2[,2])           ## responses "status"
x = list(mockgene1[,3:502],mockgene2[,3:502])   ## 500 predictors 


##Implementing fusion learning algorithm 
result &lt;- fusionbinary(x,y,0.3,N=c(98,286),500,2) 
id &lt;- which(result$beta[,1]!=0)+2
genename &lt;- colnames(mockgene1)[id]

</code></pre>


</div>