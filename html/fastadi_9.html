<div class="container">

<table style="width: 100%;"><tr>
<td>citation_impute</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>CitationImpute</h2>

<h3>Description</h3>

<p>An implementation of the <code>AdaptiveImpute</code> algorithm using efficient
sparse matrix computations, specialized for the case when missing
values in the upper triangle are taken to be <em>explicitly observed</em>
zeros, as opposed to missing values. This is primarily
useful for spectral decompositions of adjacency matrices of graphs
with (near) tree structure, such as citation networks.
</p>


<h3>Usage</h3>

<pre><code class="language-R">citation_impute(
  X,
  rank,
  ...,
  initialization = c("svd", "adaptive-initialize", "approximate"),
  max_iter = 200L,
  check_interval = 1L,
  epsilon = 1e-07,
  additional = NULL
)

## S3 method for class 'sparseMatrix'
citation_impute(
  X,
  rank,
  ...,
  initialization = c("svd", "adaptive-initialize", "approximate"),
  additional = NULL
)

## S3 method for class 'LRMF'
citation_impute(
  X,
  rank,
  ...,
  epsilon = 1e-07,
  max_iter = 200L,
  check_interval = 1L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A <em>square</em> sparse matrix of <code>Matrix::sparseMatrix()</code> class.
Implicit zeros in the upper triangle of this matrix are considered
observed and predictions on these elements contribute to the
objective function minimized by <code>AdaptiveImpute</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rank</code></td>
<td>
<p>Desired rank (integer) to use in the low rank approximation.
Must be at least <code>2L</code> and at most the rank of <code>X</code>. Note that the rank
of <code>X</code> is typically unobserved and computations may be unstable or
even fail when <code>rank</code> is near or exceeds this threshold.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Unused additional arguments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initialization</code></td>
<td>
<p>How to initialize the low rank approximation.
Options are:
</p>

<ul>
<li> <p><code>"svd"</code> (default). In the initialization step, this treats
unobserved values as zeroes.
</p>
</li>
<li> <p><code>"adaptive-initialize"</code>. In the initialization step, this treats
unobserved values as actually unobserved. However, the current
<code>AdaptiveInitialize</code> implementation relies on dense matrix
computations that are only suitable for relatively small matrices.
</p>
</li>
<li> <p><code>"approximate"</code>. An approximate variant of <code>AdaptiveInitialize</code>
that is less computationally expensive. See <code>adaptive_initialize</code>
for details.
</p>
</li>
</ul>
<p>Note that initialization matters as <code>AdaptiveImpute</code> optimizes
a non-convex objective. The current theory shows that initializing
with <code>AdaptiveInitialize</code> leads to a consistent estimator, but it
isn't know if this is the case for SVD initialization. Empirically
we have found that SVD initialization works well nonetheless.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>Maximum number of iterations to perform (integer). Defaults
to <code>200L</code>. In practice 10 or so iterations will get you a decent
approximation to use in exploratory analysis, and and 50-100 will get
you most of the way to convergence. Must be at least <code>1L</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check_interval</code></td>
<td>
<p>Integer specifying how often to perform convergence
checks. Defaults to <code>1L</code>. In practice, check for convergence requires
a norm calculation that is expensive for large matrices and decreasing
the frequency of convergence checks will reduce computation time. Can
also be set to <code>NULL</code>, which case <code>max_iter</code> iterations of the algorithm
will occur with no possibility of stopping due to small relative change
in the imputed matrix. In this case <code>delta</code> will be reported as <code>Inf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>Convergence criteria, measured in terms of relative change
in Frobenius norm of the full imputed matrix. Defaults to <code>1e-7</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>additional</code></td>
<td>
<p>Ignored except when <code>alpha_method = "approximate"</code>
in which case it controls the precise of the approximation to <code>alpha</code>.
The approximate computation of <code>alpha</code> will always understand <code>alpha</code>,
but the approximation will be better for larger values of <code>additional</code>.
We recommend making <code>additional</code> as large as computationally tolerable.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If OpenMP is available, <code>citation_impute</code> will automatically
use <code>getOption("Ncpus", 1L)</code> OpenMP threads to parallelize some
key computations. Note that some computations are performed with
the Armadillo C++ linear algebra library and may also be parallelized
dependent on your BLAS and LAPACK installations and configurations.
</p>


<h3>Value</h3>

<p>A low rank matrix factorization represented by an
<code>adaptive_imputation()</code> object.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# create a (binary) square sparse matrix to demonstrate on

set.seed(887)

n &lt;- 10
A &lt;- rsparsematrix(n, n, 0.1, rand.x = NULL)

mf &lt;- citation_impute(A, rank = 3L, max_iter = 1L, check_interval = NULL)
mf


</code></pre>


</div>