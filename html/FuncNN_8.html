<div class="container">

<table style="width: 100%;"><tr>
<td>fnn.tune</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tuning Functional Neural Networks</h2>

<h3>Description</h3>

<p>A convenience function for the user that implements a simple grid search for the purpose of tuning. For each combination
in the grid, a cross-validated error is calculated. The best combination is returned along with additional information.
This function only works for scalar responses.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fnn.tune(
  tune_list,
  resp,
  func_cov,
  scalar_cov = NULL,
  basis_choice,
  domain_range,
  batch_size = 32,
  decay_rate = 0,
  nfolds = 5,
  cores = 4,
  raw_data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tune_list</code></td>
<td>
<p>This is a list object containing the values from which to develop the grid. For each of the hyperparameters
that can be tuned for (<code>num_hidden_layers</code>, <code>neurons</code>, <code>epochs</code>, <code>val_split</code>, <code>patience</code>, <code>learn_rate</code>, <code>num_basis</code>,
<code>activation_choice</code>), the user inputs a set of values to try. Note that the combinations are found based on the number of
hidden layers. For example, if <code>num_hidden_layers</code> = 3 and <code>neurons</code> = c(8, 16), then the combinations will begin as
c(8, 8, 8), c(8, 8, 16), ..., c(16, 16, 16). Example provided below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resp</code></td>
<td>
<p>For scalar responses, this is a vector of the observed dependent variable. For functional responses,
this is a matrix where each row contains the basis coefficients defining the functional response (for each observation).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>func_cov</code></td>
<td>
<p>The form of this depends on whether the <code>raw_data</code> argument is true or not. If true, then this is
a list of k matrices. The dimensionality of the matrices should be the same (n x p) where n is the number of
observations and p is the number of longitudinal observations. If <code>raw_data</code> is false, then the input should be a tensor
with dimensionality b x n x k where b is the number of basis functions used to define the functional covariates, n is
the number of observations, and k is the number of functional covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scalar_cov</code></td>
<td>
<p>A matrix contained the multivariate information associated with the data set. This is all of your
non-longitudinal data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>basis_choice</code></td>
<td>
<p>A vector of size k (the number of functional covariates) with either "fourier" or "bspline" as the inputs.
This is the choice for the basis functions used for the functional weight expansion. If you only specify one, with k &gt; 1,
then the argument will repeat that choice for all k functional covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Size of the batch for stochastic gradient descent.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decay_rate</code></td>
<td>
<p>A modification to the learning rate that decreases the learning rate as more and more learning
iterations are completed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of folds to be used in the cross-validation process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>For the purpose of parallelization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>raw_data</code></td>
<td>
<p>If TRUE, then user does not need to create functional observations beforehand. The function will
internally take care of that pre-processing.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following are returned:
</p>
<p><code>Parameters</code> – The final list of hyperparameter chosen by the tuning process.
</p>
<p><code>All_Information</code> – A list object containing the errors for every combination in the grid. Each element of the list
corresponds to a different choice of number of hidden layers.
</p>
<p><code>Best_Per_Layer</code> – An object that returns the best parameter combination for each choice of hidden layers.
</p>
<p><code>Grid_List</code> – An object containing information about all combinations tried by the tuning process.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# libraries
library(fda)

# Loading data
data("daily")

# Obtaining response
total_prec = apply(daily$precav, 2, mean)

# Creating functional data
temp_data = array(dim = c(65, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), 65)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)

# Data set up
temp_data[,,1] = temp_fd$coefs

# Creating grid
tune_list_weather = list(num_hidden_layers = c(2),
                         neurons = c(8, 16),
                         epochs = c(250),
                         val_split = c(0.2),
                         patience = c(15),
                         learn_rate = c(0.01, 0.1),
                         num_basis = c(7),
                         activation_choice = c("relu", "sigmoid"))

# Running Tuning
weather_tuned = fnn.tune(tune_list_weather,
                         total_prec,
                         temp_data,
                         basis_choice = c("fourier"),
                         domain_range = list(c(1, 24)),
                         nfolds = 2)

# Looking at results
weather_tuned


</code></pre>


</div>