<div class="container">

<table style="width: 100%;"><tr>
<td>flamCV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fit the Fused Lasso Additive Model and Do Tuning Parameter Selection using K-Fold Cross-Validation
</h2>

<h3>Description</h3>

<p>Fit an additive model where each component is estimated to piecewise constant with a small number of adaptively-chosen knots. Tuning parameter selection is done using K-fold cross-validation. In particular, this function implements the "fused lasso additive model", as proposed in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Usage</h3>

<pre><code class="language-R">flamCV(x, y, lambda.min.ratio = 0.01, n.lambda = 50, lambda.seq = NULL,
alpha = 1, family = "gaussian", method = "BCD", fold = NULL,
n.fold = NULL, seed = NULL, within1SE = T, tolerance = 10e-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>n x p covariate matrix. May have p &gt; n.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>n-vector containing the outcomes for the n observations in <code>x</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.ratio</code></td>
<td>

<p>smallest value for <code>lambda.seq</code>, as a fraction of the maximum lambda value, which is the data-derived smallest value for which all estimated functions are zero. The default is 0.01.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.lambda</code></td>
<td>

<p>the number of lambda values to consider - the default is 50.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.seq</code></td>
<td>

<p>a user-supplied sequence of positive lambda values to consider. The typical usage is to calculate <code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>, but providing <code>lambda.seq</code> overrides this. If provided, <code>lambda.seq</code> should be a decreasing sequence of values, since <code>flamCV</code> relies on warm starts for speed. Thus fitting the model for a whole sequence of lambda values is often faster than fitting for a single lambda value.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>the value of the tuning parameter alpha to consider - default is 1. Value must be in [0,1] with values near 0 prioritizing sparsity of functions and values near 1 prioritizing limiting the number of knots. Empirical evidence suggests using alpha of 1 when p &lt; n and alpha of 0.75 when p &gt; n.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>

<p>specifies the loss function to use. Currently supports squared error loss (default; <code>family="gaussian"</code>) and logistic loss (<code>family="binomial"</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>specifies the optimization algorithm to use. Options are block-coordinate descent (default; <code>method="BCD"</code>), generalized gradient descent (<code>method="GGD"</code>), or generalized gradient descent with backtracking (<code>method="GGD.backtrack"</code>).  This argument is ignored if <code>family="binomial"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>

<p>user-supplied fold numbers for cross-validation. If supplied, <code>fold</code> should be an n-vector with entries in 1,...,K when doing K-fold cross-validation. The default is to choose <code>fold</code> using <code>n.fold</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.fold</code></td>
<td>

<p>the number of folds, K, to use for the K-fold cross-validation selection of tuning parameters. The default is 10 - specification of <code>fold</code> overrides use of <code>n.fold</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>an optional number used with <code>set.seed()</code> at the beginning of the function. This is only relevant if <code>fold</code> is not specified by the user.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>within1SE</code></td>
<td>

<p>logical (<code>TRUE</code> or <code>FALSE</code>) for how cross-validated tuning parameters should be chosen. If <code>within1SE=TRUE</code>, lambda is chosen to be the value corresponding to the most sparse model with cross-validation error within one standard error of the minimum cross-validation error. If <code>within1SE=FALSE</code>, lambda is chosen to be the value corresponding to the minimum cross-validation error.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tolerance</code></td>
<td>

<p>specifies the convergence criterion for the objective (default is 10e-6).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Note that <code>flamCV</code> does not cross-validate over <code>alpha</code> - just a single value should be provided. However, if the user would like to cross-validate over <code>alpha</code>, then <code>flamCV</code> should be called multiple times for different values of <code>alpha</code> and the same <code>seed</code>. This ensures that the cross-validation folds (<code>fold</code>) remain the same for the different values of <code>alpha</code>. See the example below for details.
</p>


<h3>Value</h3>

<p>An object with S3 class "flamCV".
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mean.cv.error</code></td>
<td>
<p>m-vector containing cross-validation error where m is the length of <code>lambda.seq</code>. Note that <code>mean.cv.error[i]</code> contains the cross-validation error for tuning parameters <code>alpha</code> and <code>flam.out$all.lambda[i]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se.cv.error</code></td>
<td>
<p>m-vector containing cross-validation standard error where m is the length of <code>lambda.seq</code>. Note that <code>se.cv.error[i]</code> contains the standard error of the cross-validation error for tuning parameters <code>alpha</code> and <code>flam.out$all.lambda[i]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.cv</code></td>
<td>
<p>optimal lambda value chosen by cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>as specified by user (or default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index.cv</code></td>
<td>
<p>index of the model corresponding to 'lambda.cv'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>flam.out</code></td>
<td>
<p>object of class 'flam' returned by <code>flam</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>as specified by user (or default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.folds</code></td>
<td>
<p>as specified by user (or default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>within1SE</code></td>
<td>
<p>as specified by user (or default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tolerance</code></td>
<td>
<p>as specified by user (or default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>matched call.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code>flam</code>, <code>plot.flamCV</code>, <code>summary.flamCV</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)

#fit model for a range of lambda chosen by default
#pick lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, alpha = 0.75, n.fold = 2)

## Not run: 
#note that cross-validation is only done to choose lambda for specified alpha
#to cross-validate over alpha also, call 'flamCV' for several alpha and set seed
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out1 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.65, seed = 100, 
	within1SE = FALSE, n.fold = 2)
flamCV.out2 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.75, seed = 100, 
	within1SE = FALSE, n.fold = 2)
flamCV.out3 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.85, seed = 100, 
	within1SE = FALSE, n.fold = 2)
#this ensures that the folds used are the same
flamCV.out1$fold; flamCV.out2$fold; flamCV.out3$fold
#compare the CV error for the optimum lambda of each alpha to choose alpha
CVerrors &lt;- c(flamCV.out1$mean.cv.error[flamCV.out1$index.cv], 
	flamCV.out2$mean.cv.error[flamCV.out2$index.cv], 
	flamCV.out3$mean.cv.error[flamCV.out3$index.cv])
best.alpha &lt;- c(flamCV.out1$alpha, flamCV.out2$alpha, 
	flamCV.out3$alpha)[which(CVerrors==min(CVerrors))]

#also can generate data for logistic FLAM model
data2 &lt;- sim.data(n = 50, scenario = 1, zerof = 10, family = "binomial")
#fit the FLAM model with cross-validation using logistic loss
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.logistic.out &lt;- flamCV(x = data2$x, y = data2$y, family = "binomial",
	n.fold = 2)

## End(Not run)

#'flamCV' returns an object of the class 'flamCV' that includes an object
#of class 'flam' (flam.out); see ?'flam-package' for an example using S3
#methods for the classes of 'flam' and 'flamCV'
</code></pre>


</div>