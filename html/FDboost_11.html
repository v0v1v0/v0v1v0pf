<div class="container">

<table style="width: 100%;"><tr>
<td>bsignal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Base-learners for Functional Covariates</h2>

<h3>Description</h3>

<p>Base-learners that fit effects of functional covariates.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bsignal(
  x,
  s,
  index = NULL,
  inS = c("smooth", "linear", "constant"),
  knots = 10,
  boundary.knots = NULL,
  degree = 3,
  differences = 1,
  df = 4,
  lambda = NULL,
  center = FALSE,
  cyclic = FALSE,
  Z = NULL,
  penalty = c("ps", "pss"),
  check.ident = FALSE
)

bconcurrent(
  x,
  s,
  time,
  index = NULL,
  knots = 10,
  boundary.knots = NULL,
  degree = 3,
  differences = 1,
  df = 4,
  lambda = NULL,
  cyclic = FALSE
)

bhist(
  x,
  s,
  time,
  index = NULL,
  limits = "s&lt;=t",
  standard = c("no", "time", "length"),
  intFun = integrationWeightsLeft,
  inS = c("smooth", "linear", "constant"),
  inTime = c("smooth", "linear", "constant"),
  knots = 10,
  boundary.knots = NULL,
  degree = 3,
  differences = 1,
  df = 4,
  lambda = NULL,
  penalty = c("ps", "pss"),
  check.ident = FALSE
)

bfpc(
  x,
  s,
  index = NULL,
  df = 4,
  lambda = NULL,
  penalty = c("identity", "inverse", "no"),
  pve = 0.99,
  npc = NULL,
  npc.max = 15,
  getEigen = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix of functional variable x(s). The functional covariate has to be 
supplied as n by &lt;no. of evaluations&gt; matrix, i.e., each row is one functional observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>vector for the index of the functional variable x(s) giving the 
measurement points of the functional covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>a vector of integers for expanding the covariate in <code>x</code> 
For example, <code>bsignal(X, s, index = index)</code> is equal to <code>bsignal(X[index,], s)</code>, 
where index is an integer of length greater or equal to <code>NROW(x)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inS</code></td>
<td>
<p>the functional effect can be smooth, linear or constant in s, 
which is the index of the functional covariates x(s).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knots</code></td>
<td>
<p>either the number of knots or a vector of the positions 
of the interior knots (for more details see <code>bbs</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boundary.knots</code></td>
<td>
<p>boundary points at which to anchor the B-spline basis 
(default the range of the data). A vector (of length 2) 
for the lower and the upper boundary knot can be specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degree</code></td>
<td>
<p>degree of the regression spline.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>differences</code></td>
<td>
<p>a non-negative integer, typically 1, 2 or 3. Defaults to 1.
If <code>differences</code> = <em>k</em>, <em>k</em>-th-order differences are used as 
a penalty (<em>0</em>-th order differences specify a ridge penalty).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>trace of the hat matrix for the base-learner defining the 
base-learner complexity. Low values of <code>df</code> correspond to a 
large amount of smoothing and thus to "weaker" base-learners.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>smoothing parameter of the penalty, computed from <code>df</code> when <code>df</code> is specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>See <code>bbs</code>. 
The effect is re-parameterized such that the unpenalized part of the fit is subtracted and only 
the penalized effect is fitted, using a spectral decomposition of the penalty matrix.  
The unpenalized, parametric part has then to be included in separate 
base-learners using <code>bsignal(..., inS = 'constant')</code> or <code>bsignal(..., inS = 'linear')</code> 
for first (<code>difference = 1</code>) and second (<code>difference = 2</code>) order difference penalty respectively. 
See the help on the argument <code>center</code> of <code>bbs</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cyclic</code></td>
<td>
<p>if <code>cyclic = TRUE</code> the fitted coefficient function coincides at the boundaries 
(useful for cyclic covariates such as day time etc.).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>a transformation matrix for the design-matrix over the index of the covariate.
<code>Z</code> can be calculated as the transformation matrix for a sum-to-zero constraint in the case
that all trajectories have the same mean 
(then a shift in the coefficient function is not identifiable).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>for <code>bsignal</code>, by default, <code>penalty = "ps"</code>, the difference penalty for P-splines is used, 
for <code>penalty = "pss"</code> the penalty matrix is transformed to have full rank, 
so called shrinkage approach by Marra and Wood (2011). 
For <code>bfpc</code> the penalty can be either <code>"identity"</code> for a ridge penalty 
(the default) or <code>"inverse"</code> to use the matrix with the inverse eigenvalues 
on the diagonal as penalty matrix or <code>"no"</code> for no penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check.ident</code></td>
<td>
<p>use checks for identifiability of the effect, based on Scheipl and Greven (2016) 
for linear functional effect using <code>bsignal</code> and 
based on Brockhaus et al. (2017) for historical effects using <code>bhist</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time</code></td>
<td>
<p>vector for the index of the functional response y(time) 
giving the measurement points of the functional response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limits</code></td>
<td>
<p>defaults to <code>"s&lt;=t"</code> for an historical effect with s&lt;=t;
either one of <code>"s&lt;t"</code> or <code>"s&lt;=t"</code> for [l(t), u(t)] = [T1, t]; 
otherwise specify limits as a function for integration limits [l(t), u(t)]: 
function that takes <code class="reqn">s</code> as the first and <code>t</code> as the second argument and returns 
<code>TRUE</code> for combinations of values (s,t) if <code class="reqn">s</code> falls into the integration range for 
the given <code class="reqn">t</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standard</code></td>
<td>
<p>the historical effect can be standardized with a factor. 
"no" means no standardization, "time" standardizes with the current value of time and 
"length" standardizes with the length of the integral</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intFun</code></td>
<td>
<p>specify the function that is used to compute integration weights in <code>s</code> 
over the functional covariate <code class="reqn">x(s)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inTime</code></td>
<td>
<p>the historical effect can be smooth, linear or constant in time, 
which is the index of the functional response y(time).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pve</code></td>
<td>
<p>proportion of variance explained by the first K functional principal components (FPCs): 
used to choose the number of functional principal components (FPCs).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npc</code></td>
<td>
<p>prespecified value for the number K of FPCs (if given, this overrides <code>pve</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npc.max</code></td>
<td>
<p>maximal number K of FPCs to use; defaults to 15.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>getEigen</code></td>
<td>
<p>save the eigenvalues and eigenvectors, defaults to <code>TRUE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>bsignal()</code> implements a base-learner for functional covariates to  
estimate an effect of the form <code class="reqn">\int x_i(s)\beta(s)ds</code>. Defaults to a cubic  
B-spline basis with first difference penalties for <code class="reqn">\beta(s)</code> and numerical 
integration over the entire range by using trapezoidal Riemann weights. 
If <code>bsignal()</code> is used within <code>FDboost()</code>, the base-learner of 
<code>timeformula</code> is attached, resulting in an effect varying over the index
of the response <code class="reqn">\int x_i(s)\beta(s, t)ds</code> if <code>timeformula = bbs(t)</code>. 
The functional variable must be observed on one common grid <code>s</code>.  
</p>
<p><code>bconcurrent()</code> implements a concurrent effect for a functional covariate
on a functional response, i.e., an effect of the form <code class="reqn">x_i(t)\beta(t)</code> for
a functional response <code class="reqn">Y_i(t)</code> and concurrently observed covariate <code class="reqn">x_i(t)</code>. 
<code>bconcurrent()</code> can only be used if <code class="reqn">Y(t)</code> and <code class="reqn">x(s)</code> are observed over
the same domain <code class="reqn">s,t \in [T1, T2]</code>.  
</p>
<p><code>bhist()</code> implements a base-learner for functional covariates with 
flexible integration limits <code>l(t)</code>, <code>r(t)</code> and the possibility to
standardize the effect by <code>1/t</code> or the length of the integration interval. 
The effect is <code class="reqn">stand * \int_{l(t)}^{r_{t}} x(s)\beta(t,s)ds</code>, where <code class="reqn">stand</code> is 
the chosen standardization which defaults to 1. 
The base-learner defaults to a historical effect of the form 
<code class="reqn">\int_{T1}^{t} x_i(s)\beta(t,s)ds</code>, 
where <code class="reqn">T1</code> is the minimal index of <code class="reqn">t</code> of the response <code class="reqn">Y(t)</code>. 
The functional covariate must be observed on one common grid <code>s</code>.  
See Brockhaus et al. (2017) for details on historical effects.   
</p>
<p><code>bfpc()</code> is a base-learner for a linear effect of functional covariates based on 
functional principal component analysis (FPCA). 
For the functional linear effect <code class="reqn">\int x_i(s)\beta(s)ds</code> the functional covariate 
and the coefficient function are both represented by a FPC basis. 
The functional covariate
<code class="reqn">x(s)</code> is decomposed into <code class="reqn">x(s) \approx \sum_{k=1}^K \xi_{ik} \Phi_k(s)</code> using 
<code>fpca.sc</code> for the truncated Karhunen-Loeve decomposition. 
Then <code class="reqn">\beta(s)</code> is represented in the function
space spanned by <code class="reqn">\Phi_k(s)</code>, k=1,...,K, see Scheipl et al. (2015) for details. 
As penalty matrix, the identity matrix is used. 
The implementation is similar to <code>ffpc</code>.  
</p>
<p>It is recommended to use centered functional covariates with 
<code class="reqn">\sum_i x_i(s) = 0</code> for all <code class="reqn">s</code> in <code>bsignal()</code>-, 
<code>bhist()</code>- and <code>bconcurrent()</code>-terms. 
For centered covariates, the effects are centered per time-point of the response. 
If all effects are centered, the functional intercept 
can be interpreted as the global mean function. 
</p>
<p>The base-learners for functional covariates cannot deal with any missing 
values in the covariates.
</p>


<h3>Value</h3>

<p>Equally to the base-learners of package <code>mboost</code>: 
</p>
<p>An object of class <code>blg</code> (base-learner generator) with a 
<code>dpp()</code> function (dpp, data pre-processing). 
</p>
<p>The call of <code>dpp()</code> returns an object of class 
<code>bl</code> (base-learner) with a <code>fit()</code> function. The call to 
<code>fit()</code> finally returns an object of class <code>bm</code> (base-model).
</p>


<h3>References</h3>

<p>Brockhaus, S., Scheipl, F., Hothorn, T. and Greven, S. (2015): 
The functional linear array model. Statistical Modelling, 15(3), 279-300.
</p>
<p>Brockhaus, S., Melcher, M., Leisch, F. and Greven, S. (2017): 
Boosting flexible functional regression models with a high number of functional historical effects,  
Statistics and Computing, 27(4), 913-926.   
</p>
<p>Marra, G. and Wood, S.N. (2011): Practical variable selection for generalized additive models. 
Computational Statistics &amp; Data Analysis, 55, 2372-2387.
</p>
<p>Scheipl, F., Staicu, A.-M. and Greven, S. (2015): 
Functional Additive Mixed Models, Journal of Computational and Graphical Statistics, 24(2), 477-501. 
</p>
<p>Scheipl, F. and Greven, S. (2016): Identifiability in penalized function-on-function regression models. 
Electronic Journal of Statistics, 10(1), 495-526.
</p>


<h3>See Also</h3>

<p><code>FDboost</code> for the model fit.
</p>


<h3>Examples</h3>

<pre><code class="language-R">######## Example for scalar-on-function-regression with bsignal()  
data("fuelSubset", package = "FDboost")

## center the functional covariates per observed wavelength
fuelSubset$UVVIS &lt;- scale(fuelSubset$UVVIS, scale = FALSE)
fuelSubset$NIR &lt;- scale(fuelSubset$NIR, scale = FALSE)

## to make mboost:::df2lambda() happy (all design matrix entries &lt; 10)
## reduce range of argvals to [0,1] to get smaller integration weights
fuelSubset$uvvis.lambda &lt;- with(fuelSubset, (uvvis.lambda - min(uvvis.lambda)) /
                                  (max(uvvis.lambda) - min(uvvis.lambda) ))
fuelSubset$nir.lambda &lt;- with(fuelSubset, (nir.lambda - min(nir.lambda)) /
                                (max(nir.lambda) - min(nir.lambda) ))

## model fit with scalar response and two functional linear effects 
## include no intercept 
## as all base-learners are centered around 0 
mod2 &lt;- FDboost(heatan ~ bsignal(UVVIS, uvvis.lambda, knots = 40, df = 4, check.ident = FALSE) 
               + bsignal(NIR, nir.lambda, knots = 40, df=4, check.ident = FALSE), 
               timeformula = NULL, data = fuelSubset) 
summary(mod2) 

 
###############################################
### data simulation like in manual of pffr::ff

if(require(refund)){

#########
# model with linear functional effect, use bsignal()
# Y(t) = f(t) + \int X1(s)\beta(s,t)ds + eps
set.seed(2121)
data1 &lt;- pffrSim(scenario = "ff", n = 40)
data1$X1 &lt;- scale(data1$X1, scale = FALSE)
dat_list &lt;- as.list(data1)
dat_list$t &lt;- attr(data1, "yindex")
dat_list$s &lt;- attr(data1, "xindex")

## model fit by FDboost 
m1 &lt;- FDboost(Y ~ 1 + bsignal(x = X1, s = s, knots = 5), 
              timeformula = ~ bbs(t, knots = 5), data = dat_list, 
              control = boost_control(mstop = 21))

## search optimal mSTOP

  set.seed(123)
  cv &lt;- validateFDboost(m1, grid = 1:100) # 21 iterations


## model fit by pffr
t &lt;- attr(data1, "yindex")
s &lt;- attr(data1, "xindex")
m1_pffr &lt;- pffr(Y ~ ff(X1, xind = s), yind = t, data = data1)


  oldpar &lt;- par(mfrow = c(2, 2))
  plot(m1, which = 1); plot(m1, which = 2) 
  plot(m1_pffr, select = 1, shift = m1_pffr$coefficients["(Intercept)"]) 
  plot(m1_pffr, select = 2)
  par(oldpar)



############################################
# model with functional historical effect, use bhist() 
# Y(t) = f(t)  + \int_0^t X1(s)\beta(s,t)ds + eps
set.seed(2121)
mylimits &lt;- function(s, t){
  (s &lt; t) | (s == t)
}
data2 &lt;- pffrSim(scenario = "ff", n = 40, limits = mylimits)
data2$X1 &lt;- scale(data2$X1, scale = FALSE)
dat2_list &lt;- as.list(data2)
dat2_list$t &lt;- attr(data2, "yindex")
dat2_list$s &lt;- attr(data2, "xindex")

## model fit by FDboost 
m2 &lt;- FDboost(Y ~ 1 + bhist(x = X1, s = s, time = t, knots = 5), 
              timeformula = ~ bbs(t, knots = 5), data = dat2_list, 
              control = boost_control(mstop = 40))
              
## search optimal mSTOP

  set.seed(123)
  cv2 &lt;- validateFDboost(m2, grid = 1:100) # 40 iterations
               

## model fit by pffr
t &lt;- attr(data2, "yindex")
s &lt;- attr(data2, "xindex")
m2_pffr &lt;- pffr(Y ~ ff(X1, xind = s, limits = "s&lt;=t"), yind = t, data = data2)


oldpar &lt;- par(mfrow = c(2, 2))
plot(m2, which = 1); plot(m2, which = 2)
## plot of smooth intercept does not contain m1_pffr$coefficients["(Intercept)"]
plot(m2_pffr, select = 1, shift = m2_pffr$coefficients["(Intercept)"]) 
plot(m2_pffr, select = 2) 
par(oldpar)



}


</code></pre>


</div>