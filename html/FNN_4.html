<div class="container">

<table style="width: 100%;"><tr>
<td>get.knn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Search Nearest Neighbors</h2>

<h3>Description</h3>

<p>Fast k-nearest neighbor searching algorithms including a kd-tree, cover-tree
and the algorithm implemented in class package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  get.knn(data, k=10, algorithm=c("kd_tree", "cover_tree", "CR", "brute"))
  get.knnx(data, query, k=10, algorithm=c("kd_tree", "cover_tree",
	  "CR", "brute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an input data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>query</code></td>
<td>
<p>a query data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>nearest neighbor searching algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the maximum number of nearest neighbors to search. The default value
is set to 10.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <em>cover tree</em> is O(n) space data structure which allows us to answer queries
in the same O(log(n)) time as <em>kd tree</em> given a fixed intrinsic dimensionality.
Templated code from <a href="https://hunch.net/~jl/projects/cover_tree/cover_tree.html">https://hunch.net/~jl/projects/cover_tree/cover_tree.html</a> is used.
</p>
<p>The <em>kd tree</em> algorithm is implemented in the Approximate Near Neighbor (ANN) C++ library (see <a href="http://www.cs.umd.edu/~mount/ANN/">http://www.cs.umd.edu/~mount/ANN/</a>).
The exact nearest neighbors are searched in this package.
</p>
<p>The <em>CR</em> algorithm is the <em>VR</em> using distance <em>1-x'y</em> assuming <code>x</code> and <code>y</code> are unit vectors.
The <em>brute</em> algorithm searches linearly. It is a naive method.
</p>


<h3>Value</h3>

<p>a list contains:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>nn.index</code></td>
<td>
<p>an n x k matrix for the nearest neighbor indice.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nn.dist</code></td>
<td>
<p>an n x k matrix for the nearest neighbor Euclidean distances.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:lishengqiao@yahoo.com">lishengqiao@yahoo.com</a></p>


<h3>References</h3>

<p>Bentley J.L. (1975), “Multidimensional binary search trees used for associative
search,” <em>Communication ACM</em>, <b>18</b>, 309-517.
</p>
<p>Arya S. and Mount D.M. (1993),
“Approximate nearest neighbor searching,”
<em>Proc. 4th Ann. ACM-SIAM Symposium on Discrete Algorithms (SODA'93)</em>, 271-280.
</p>
<p>Arya S., Mount D.M., Netanyahu N.S., Silverman R. and Wu A.Y. (1998),
“An optimal algorithm for approximate nearest neighbor searching,”
<em>Journal of the ACM</em>, <b>45</b>, 891-923.
</p>
<p>Beygelzimer A., Kakade S. and Langford J. (2006),
“Cover trees for nearest neighbor,”
<em>ACM Proc. 23rd international conference on Machine learning</em>, <b>148</b>, 97-104.
</p>


<h3>See Also</h3>

<p><code>nn2</code> in <span class="pkg">RANN</span>, <code>ann</code> in <span class="pkg">yaImpute</span> and <code>knn</code> in <span class="pkg">class</span>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  data&lt;- query&lt;- cbind(1:10, 1:10)

  get.knn(data, k=5)
  get.knnx(data, query, k=5)
  get.knnx(data, query, k=5, algo="kd_tree")

  th&lt;- runif(10, min=0, max=2*pi)
  data2&lt;-  cbind(cos(th), sin(th))
  get.knn(data2, k=5, algo="CR")

</code></pre>


</div>