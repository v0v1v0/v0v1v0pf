<div class="container">

<table style="width: 100%;"><tr>
<td>loess.as</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fit a local polynomial regression with automatic smoothing parameter selection
</h2>

<h3>Description</h3>

<p>Fit a local polynomial regression with automatic smoothing parameter selection. Two methods are available for the selection of the smoothing parameter: bias-corrected Akaike information criterion (aicc); and generalized cross-validation (gcv).
</p>


<h3>Usage</h3>

<pre><code class="language-R">loess.as(x, y, degree = 1, criterion = c("aicc", "gcv"), 
		family = c("gaussian", "symmetric"), user.span = NULL, 
		plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a vector of response values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: “aicc” denotes bias-corrected AIC criterion, “gcv” denotes generalized cross-validation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>

<p>if “gaussian” fitting is by least-squares, and if “symmetric” a re-descending M estimator is used with Tukey's biweight function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>user.span</code></td>
<td>

<p>the user-defined parameter which controls the degree of smoothing.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>

<p>if TRUE, the fitted curve or surface will be generated.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>control parameters.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Fit a local polynomial regression with automatic smoothing parameter selection. The predictor x can either one-dimensional or two-dimensional.
</p>


<h3>Value</h3>

<p>An object of class “loess”.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Cleveland, W. S. (1979) Robust locally weighted regression and smoothing scatterplots. <em>Journal of the American Statistical Association</em>. 74, 829–836.
</p>
<p>Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998), Smoothing Parameter Selection in Nonparametric Regression Using an Improved Akaike Information Criterion. <em>Journal of the Royal Statistical Society B</em>. 60, 271–293.
</p>
<p>Golub, G., Heath, M. and Wahba, G. (1979). Generalized cross validation as a method for choosing a good ridge parameter. <em>Technometrics</em>. 21, 215–224.
</p>


<h3>See Also</h3>

<p><code>loess</code>, <code>loess.ancova</code>, <code>T.L2</code>, <code>T.aov</code>, <code>T.var</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Fit Local Polynomial Regression with Automatic Smoothing Parameter Selection
n1 &lt;- 100
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x1) + e1

(y1.fit &lt;- loess.as(x1, y1, plot=TRUE))

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

(y2.fit &lt;- loess.as(cbind(x21, x22), y2, plot=TRUE))

</code></pre>


</div>