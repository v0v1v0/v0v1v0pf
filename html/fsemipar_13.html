<div class="container">

<table style="width: 100%;"><tr>
<td>IASSMR.kNN.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Impact point selection with IASSMR and kNN estimation
</h2>

<h3>Description</h3>

<p>This function implements the Improved Algorithm for Sparse Semiparametric Multi-functional Regression (IASSMR) with kNN estimation. This algorithm is specifically designed for estimating multi-functional partial linear single-index models, which incorporate multiple scalar variables and a functional covariate as predictors. These scalar variables are derived from the discretisation of a curve and have linear effects while the functional covariate exhibits a single-index effect. 
</p>
<p>IASSMR is a two-stage procedure that selects the impact points of the discretised curve and estimates the model. The algorithm employs a penalised least-squares regularisation procedure, integrated with kNN estimation using Nadaraya-Watson weights. It uses B-spline expansions to represent curves and eligible functional indexes. Additionally, it utilises an objective criterion (<code>criterion</code>) to determine the initial number of covariates in the reduced model (<code>w.opt</code>), the number of neighbours (<code>k.opt</code>), and the penalisation parameter (<code>lambda.opt</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">IASSMR.kNN.fit(x, z, y, train.1 = NULL, train.2 = NULL, 
seed.coeff = c(-1, 0, 1), order.Bspline = 3, nknot.theta = 3, knearest = NULL,
min.knn = 2, max.knn = NULL, step = NULL, range.grid = NULL, 
kind.of.kernel = "quad", nknot = NULL, lambda.min = NULL, lambda.min.h = NULL, 
lambda.min.l = NULL, factor.pn = 1, nlambda = 100, vn = ncol(z), nfolds = 10, 
seed = 123, wn = c(10, 15, 20), criterion = "GCV", penalty = "grSCAD", 
max.iter = 1000, n.core = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Matrix containing the observations of the functional covariate collected by row (functional single-index component).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>

<p>Matrix containing the observations of the functional covariate that is discretised collected by row (linear component).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Vector containing the scalar response.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train.1</code></td>
<td>

<p>Positions of the data that are used as the training sample in the 1st step. The default setting is  <code>train.1&lt;-1:ceiling(n/2)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train.2</code></td>
<td>

<p>Positions of the data that are used as the training sample in the 2nd step. The default setting is <code>train.2&lt;-(ceiling(n/2)+1):n</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed.coeff</code></td>
<td>

<p>Vector of initial values used to  build the set <code class="reqn">\Theta_n</code> (see section <code>Details</code>). The coefficients for the B-spline representation of each eligible functional index <code class="reqn">\theta \in \Theta_n</code> are obtained from <code>seed.coeff</code>.  The default is <code>c(-1,0,1)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order.Bspline</code></td>
<td>

<p>Positive integer giving the order of the B-spline basis functions. This is the number of coefficients in each piecewise polynomial segment. The default is 3.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nknot.theta</code></td>
<td>

<p>Positive integer indicating the number of regularly spaced interior knots in the B-spline expansion of <code class="reqn">\theta_0</code>. The default is 3.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knearest</code></td>
<td>

<p>Vector of positive integers containing the sequence in which the  number of nearest neighbours <code>k.opt</code> is selected. If <code>knearest=NULL</code>, then <code>knearest &lt;- seq(from =min.knn, to = max.knn, by = step)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.knn</code></td>
<td>

<p>A positive integer that represents the minimum value in the sequence for selecting the number of nearest neighbours <code>k.opt</code>. This value should be less than the sample size. The default is 2.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.knn</code></td>
<td>

<p>A positive integer that represents the maximum value in the sequence for selecting number of nearest neighbours <code>k.opt</code>. This value should be less than the sample size. The default is <code>max.knn &lt;- n%/%5</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>

<p>A positive integer used to construct the sequence of k-nearest neighbours as follows: <code>min.knn, min.knn + step, min.knn + 2*step, min.knn + 3*step,...</code>. The default value for <code>step</code> is <code>step&lt;-ceiling(n/100)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>range.grid</code></td>
<td>

<p>Vector of length 2 containing the endpoints of the grid at which the observations of the functional covariate <code>x</code> are evaluated (i.e. the range of the discretisation). If <code>range.grid=NULL</code>, then <code>range.grid=c(1,p)</code> is considered, where <code>p</code> is the discretisation size of <code>x</code> (i.e. <code>ncol(x))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kind.of.kernel</code></td>
<td>

<p>The type of kernel function used. Currently, only Epanechnikov kernel (<code>"quad"</code>) is available.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nknot</code></td>
<td>

<p>Positive integer indicating the number of interior knots for the B-spline expansion of the functional covariate. The default value is <code>(p - order.Bspline - 1)%/%2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>

<p>The smallest value for lambda (i. e., the lower endpoint  of the sequence in which <code>lambda.opt</code> is selected), as fraction of <code>lambda.max</code>.
The defaults is <code>lambda.min.l</code> if the sample size is larger than <code>factor.pn</code> times the number of linear covariates and <code>lambda.min.h</code> otherwise.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.h</code></td>
<td>

<p>The lower endpoint of the sequence in which <code>lambda.opt</code> is selected if the sample size is smaller than <code>factor.pn</code> times the number of linear covariates. The default is 0.05. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.l</code></td>
<td>

<p>The lower endpoint of the sequence in which <code>lambda.opt</code> is selected if the sample size is larger than <code>factor.pn</code> times the number of linear covariates. The default is 0.0001.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor.pn</code></td>
<td>

<p>Positive integer used to set <code>lambda.min</code>. The default value is 1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>

<p>Positive integer indicating the number of values in the sequence from which <code>lambda.opt</code> is selected. The default is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vn</code></td>
<td>

<p>Positive integer or vector of positive integers indicating the number of groups of consecutive variables to be penalised together. The default value is <code>vn=ncol(z)</code>, resulting in the individual penalization of each scalar covariate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>

<p>Number of cross-validation folds (used when <code>criterion="k-fold-CV"</code>). Default is 10.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>You may set the seed for the random number generator to ensure reproducible results (applicable when <code>criterion="k-fold-CV"</code> is used). The default seed value is 123.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wn</code></td>
<td>

<p>A vector of positive integers indicating the eligible number of covariates in the reduced model. For more information, refer to the section <code>Details</code>. The default is <code>c(10,15,20)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>

<p>The criterion used to select the tuning and regularisation parameters: <code>wn.opt</code>, <code>lambda.opt</code> and <code>k.opt</code> (also <code>vn.opt</code> if needed). Options include <code>"GCV"</code>, <code>"BIC"</code>, <code>"AIC"</code>, or <code>"k-fold-CV"</code>. The default setting is <code>"GCV"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>

<p>The penalty function applied in the penalised least-squares procedure. Currently, only "grLasso" and "grSCAD" are implemented. The default is "grSCAD".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>

<p>Maximum number of iterations allowed across the entire path. The default value is 1000.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.core</code></td>
<td>

<p>Number of CPU cores designated for parallel execution. The default is <code>n.core&lt;-availableCores(omit=1)</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The multi-functional partial linear single-index model (MFPLSIM) is given by the expression
</p>
<p style="text-align: center;"><code class="reqn">Y_i=\sum_{j=1}^{p_n}\beta_{0j}\zeta_i(t_j)+r\left(\left&lt;\theta_0,X_i\right&gt;\right)+\varepsilon_i,\ \ \ (i=1,\dots,n),</code>
</p>

<p>where: 
</p>

<ul>
<li> <p><code class="reqn">Y_i</code> represents a real random response and <code class="reqn">X_i</code> denotes a random element belonging to some separable Hilbert space <code class="reqn">\mathcal{H}</code> with inner product denoted by <code class="reqn">\left\langle\cdot,\cdot\right\rangle</code>. The second functional predictor <code class="reqn">\zeta_i</code> is assumed to be a curve defined on the interval <code class="reqn">[a,b]</code>, observed at the points <code class="reqn">a\leq t_1&lt;\dots&lt;t_{p_n}\leq b</code>. 
</p>
</li>
<li>  <p><code class="reqn">\mathbf{\beta}_0=(\beta_{01},\dots,\beta_{0p_n})^{\top}</code> is a vector of unknown real coefficients, and <code class="reqn">r(\cdot)</code> denotes a smooth unknown link function. In addition, <code class="reqn">\theta_0</code> is an unknown functional direction in <code class="reqn">\mathcal{H}</code>.  
</p>
</li>
<li> <p><code class="reqn">\varepsilon_i</code> denotes the random error.
</p>
</li>
</ul>
<p>In  the MFPLSIM, it is assumed that only a few scalar variables from the set <code class="reqn">\{\zeta(t_1),\dots,\zeta(t_{p_n})\}</code> are part of the model. Therefore, the relevant variables in the linear component (the impact points of the curve <code class="reqn">\zeta</code> on the response) must be selected, and the model estimated.
</p>
<p>In this function, the MFPLSIM is fitted using the IASSMR. The IASSMR is a  two-step procedure. For this, we divide the sample into two independent subsamples, each asymptotically half the size of the original (<code class="reqn">n_1\sim n_2\sim n/2</code>). One subsample is used in the first stage of the method, and the other in the second stage.The subsamples are defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
\mathcal{E}^{\mathbf{1}}=\{(\zeta_i,\mathcal{X}_i,Y_i),\quad i=1,\dots,n_1\},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\mathcal{E}^{\mathbf{2}}=\{(\zeta_i,\mathcal{X}_i,Y_i),\quad i=n_1+1,\dots,n_1+n_2=n\}.
</code>
</p>
 
<p>Note that these two subsamples are specified in the program through the arguments <code>train.1</code> and <code>train.2</code>. The superscript <code class="reqn">\mathbf{s}</code>, where <code class="reqn">\mathbf{s}=\mathbf{1},\mathbf{2}</code>, indicates the stage of the method in which the sample, function, variable, or parameter is involved.
</p>
<p>To explain the algorithm, we assume that the number <code class="reqn">p_n</code> of linear covariates can be expressed as follows: <code class="reqn">p_n=q_nw_n</code>, with <code class="reqn">q_n</code> and <code class="reqn">w_n</code> being integers.
</p>

<ol>
<li> <p><b>First step</b>. The FASSMR (see <code>FASSMR.kNN.fit</code>) combined with kNN estimation is applied using only the subsample <code class="reqn">\mathcal{E}^{\mathbf{1}}</code>. Specifically:
</p>

<ul>
<li>
<p> Consider a subset of the initial <code class="reqn">p_n</code> linear covariates, which contains only <code class="reqn">w_n</code> equally spaced discretized observations of  <code class="reqn">\zeta</code> covering the entire interval  <code class="reqn">[a,b]</code>. This subset is the following:
</p>
<p style="text-align: center;"><code class="reqn">
	\mathcal{R}_n^{\mathbf{1}}=\left\{\zeta\left(t_k^{\mathbf{1}}\right),\ \ k=1,\dots,w_n\right\},
</code>
</p>
 
<p>where  <code class="reqn">t_k^{\mathbf{1}}=t_{\left[(2k-1)q_n/2\right]}</code> and  <code class="reqn">\left[z\right]</code> denotes the smallest integer not less than the real number <code class="reqn">z</code>.The size (cardinality) of this subset is provided to the program in the argument <code>wn</code> (which contains a sequence of eligible sizes).
</p>
</li>
<li>
<p> Consider the following reduced model, which involves only the <code class="reqn">w_n</code> linear covariates belonging to <code class="reqn">\mathcal{R}_n^{\mathbf{1}}</code>:
</p>
<p style="text-align: center;"><code class="reqn">
	Y_i=\sum_{k=1}^{w_n}\beta_{0k}^{\mathbf{1}}\zeta_i(t_k^{\mathbf{1}})+r^{\mathbf{1}}\left(\left&lt;\theta_0^{\mathbf{1}},X_i\right&gt;\right)+\varepsilon_i^{\mathbf{1}}.
</code>
</p>

<p>The penalised least-squares variable selection procedure, with kNN estimation, is applied to the reduced model. This is done using the function <code>sfplsim.kNN.fit</code>, which requires the remaining arguments (see <code>sfplsim.kNN.fit</code>). The estimates obtained after that are the outputs of the first step of the algorithm.
</p>
</li>
</ul>
</li>
<li> <p><b>Second step</b>. The variables selected in the first step, along with those in their neighborhood, are included. The penalised least-squares procedure, combined with kNN estimation, is carried out again considering only the subsample <code class="reqn">\mathcal{E}^{\mathbf{2}}</code>. Specifically:
</p>

<ul>
<li>
<p> Consider a new set of variables:
</p>
<p style="text-align: center;"><code class="reqn">
		\mathcal{R}_n^{\mathbf{2}}=\bigcup_{\left\{k,\widehat{\beta}_{0k}^{\mathbf{1}}\not=0\right\}}\left\{\zeta(t_{(k-1)q_n+1}),\dots,\zeta(t_{kq_n})\right\}.
	</code>
</p>

<p>Denoting by <code class="reqn">r_n=\sharp(\mathcal{R}_n^{\mathbf{2}})</code>, the variables in <code class="reqn">\mathcal{R}_n^{\mathbf{2}}</code> can be renamed as follows:
</p>
<p style="text-align: center;"><code class="reqn">
		\mathcal{R}_n^{\mathbf{2}}=\left\{\zeta(t_1^{\mathbf{2}}),\dots,\zeta(t_{r_n}^{\mathbf{2}})\right\},
		</code>
</p>

</li>
<li>
<p>  Consider the following model, which involves only the linear covariates belonging to <code class="reqn">\mathcal{R}_n^{\mathbf{2}}</code>
</p>
<p style="text-align: center;"><code class="reqn">
		Y_i=\sum_{k=1}^{r_n}\beta_{0k}^{\mathbf{2}}\zeta_i(t_k^{\mathbf{2}})+r^{\mathbf{2}}\left(\left&lt;\theta_0^{\mathbf{2}},X_i\right&gt;\right)+\varepsilon_i^{\mathbf{2}}.</code>
</p>

<p>The penalised least-squares variable selection procedure, with kNN estimation, is applied to this model using the function <code>sfplsim.kNN.fit</code>. 
</p>
</li>
</ul>
</li>
</ol>
<p>The outputs of the second step are the estimates of the MFPLSIM. For further details on this algorithm, see Novo et al. (2021).
</p>
<p><b>Remark</b>: If the condition  <code class="reqn">p_n=w_n q_n</code> is not met (then <code class="reqn">p_n/w_n</code> is not an integer number), the function considers variable  <code class="reqn">q_n=q_{n,k}</code> values <code class="reqn">k=1,\dots,w_n</code>. Specifically:
</p>
<p style="text-align: center;"><code class="reqn">
	q_{n,k}= \left\{\begin{array}{ll}
	[p_n/w_n]+1 &amp;   k\in\{1,\dots,p_n-w_n[p_n/w_n]\},\\
	{[p_n/w_n]} &amp; k\in\{p_n-w_n[p_n/w_n]+1,\dots,w_n\},
	\end{array}
	\right.
</code>
</p>

<p>where <code class="reqn">[z]</code> denotes the integer part of the real number <code class="reqn">z</code>.
</p>
<p>The function supports parallel computation. To avoid it, we can set <code>n.core=1</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>Estimated scalar response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>Differences between <code>y</code> and the <code>fitted.values</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.est</code></td>
<td>
<p><code class="reqn">\hat{\mathbf{\beta}}</code> (i.e. estimate of <code class="reqn">\mathbf{\beta}_0</code> when the optimal tuning parameters <code>w.opt</code>, <code>lambda.opt</code>, <code>vn.opt</code> and <code>k.opt</code> are used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.est</code></td>
<td>
<p>Coefficients of <code class="reqn">\hat{\theta}</code> in the B-spline basis (i.e. estimate of <code class="reqn">\theta_0</code> when the optimal tuning parameters <code>w.opt</code>, <code>lambda.opt</code>, <code>vn.opt</code> and <code>k.opt</code> are used): a vector of <code>length(order.Bspline+nknot.theta)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indexes.beta.nonnull</code></td>
<td>
<p>Indexes of the non-zero <code class="reqn">\hat{\beta_{j}}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k.opt</code></td>
<td>
<p>Selected number of nearest neighbours (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.opt</code></td>
<td>
<p>Selected initial number of covariates in the reduced model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.opt</code></td>
<td>
<p>Selected value of the penalisation parameter <code class="reqn">\lambda</code> (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>IC</code></td>
<td>
<p>Value of the criterion function considered to select <code>w.opt</code>, <code>lambda.opt</code>, <code>vn.opt</code> and <code>k.opt</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vn.opt</code></td>
<td>
<p>Selected value of <code>vn</code> in the second step (when <code>w.opt</code> is considered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta2</code></td>
<td>
<p>Estimate of <code class="reqn">\mathbf{\beta}_0^{\mathbf{2}}</code> for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta2</code></td>
<td>
<p>Estimate of <code class="reqn">\theta_0^{\mathbf{2}}</code> for each value of the sequence <code>wn</code> (i.e. its coefficients in the B-spline basis).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indexes.beta.nonnull2</code></td>
<td>
<p>Indexes of the non-zero linear coefficients after the step 2 of the method for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knn2</code></td>
<td>
<p>Selected number of neighbours in the second step of the algorithm for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>IC2</code></td>
<td>
<p>Optimal value of the criterion function in the second step for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda2</code></td>
<td>
<p>Selected value of penalisation parameter in the second step for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index02</code></td>
<td>
<p>Indexes of the covariates (in the entire set of <code class="reqn">p_n</code>) used to build <code class="reqn">\mathcal{R}_n^{\mathbf{2}}</code> for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta1</code></td>
<td>
<p>Estimate of <code class="reqn">\mathbf{\beta}_0^{\mathbf{1}}</code> for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta1</code></td>
<td>
<p>Estimate of <code class="reqn">\theta_0^{\mathbf{1}}</code> for each value of the sequence <code>wn</code> (i.e. its coefficients in the B-spline basis).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knn1</code></td>
<td>
<p>Selected number of neighbours in the first step of the algorithm for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>IC1</code></td>
<td>
<p>Optimal value of the criterion function in the first step for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda1</code></td>
<td>
<p>Selected value of penalisation parameter in the first step for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index01</code></td>
<td>
<p>Indexes of the covariates (in the whole set of <code class="reqn">p_n</code>) used to build <code class="reqn">\mathcal{R}_n^{\mathbf{1}}</code> for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index1</code></td>
<td>
<p>Indexes of the non-zero linear coefficients after the step 1 of the method for each value of the sequence <code>wn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>German Aneiros Perez <a href="mailto:german.aneiros@udc.es">german.aneiros@udc.es</a> 
</p>
<p>Silvia Novo Diaz  <a href="mailto:snovo@est-econ.uc3m.es">snovo@est-econ.uc3m.es</a>
</p>


<h3>References</h3>

<p>Novo, S., Vieu, P., and Aneiros, G., (2021) Fast and efficient algorithms for
sparse semiparametric bi-functional regression. <em>Australian and New Zealand
Journal of Statistics</em>, <b>63</b>, 606–638, <a href="https://doi.org/10.1111/anzs.12355">doi:10.1111/anzs.12355</a>.
</p>


<h3>See Also</h3>

<p>See also <code>sfplsim.kNN.fit, predict.IASSMR.kNN</code>, <code>plot.IASSMR.kNN</code> and <code>FASSMR.kNN.fit</code>.
</p>
<p>Alternative method <code>IASSMR.kernel.fit</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Sugar)

y&lt;-Sugar$ash
x&lt;-Sugar$wave.290
z&lt;-Sugar$wave.240

#Outliers
index.y.25 &lt;- y &gt; 25
index.atip &lt;- index.y.25
(1:268)[index.atip]

#Dataset to model
x.sug &lt;- x[!index.atip,]
z.sug&lt;- z[!index.atip,]
y.sug &lt;- y[!index.atip]

train&lt;-1:216

ptm=proc.time()
fit&lt;- IASSMR.kNN.fit(x=x.sug[train,],z=z.sug[train,], y=y.sug[train],
        train.1=1:108,train.2=109:216,nknot.theta=2,lambda.min.h=0.07, 
        lambda.min.l=0.07, max.knn=20, nknot=20,criterion="BIC", max.iter=5000)
proc.time()-ptm

fit 
names(fit)

</code></pre>


</div>