<div class="container">

<table style="width: 100%;"><tr>
<td>BIC.flexsurvreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian Information Criterion (BIC) for comparison of flexsurvreg models</h2>

<h3>Description</h3>

<p>Bayesian Information Criterion (BIC) for comparison of flexsurvreg models
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'flexsurvreg'
BIC(object, cens = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Fitted model returned by <code>flexsurvreg</code>
(or <code>flexsurvspline</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cens</code></td>
<td>
<p>Include censored observations in the sample size term
(<code>n</code>) used in the calculation of BIC.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other arguments (currently unused).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There is no "official" definition of what the sample size
should be for the use of BIC in censored survival analysis.  BIC
is based on an approximation to Bayesian model comparison using
Bayes factors and an implicit vague prior.  Informally, the
sample size describes the number of "units" giving rise to a
distinct piece of information (Kass and Raftery 1995).  However
censored observations provide less information than observed
events, in principle.  The default used here is the number of
individuals, for consistency with more familiar kinds of
statistical modelling.  However if censoring is heavy, then the
number of events may be a better represent the amount of
information.  Following these principles, the best approximation
would be expected to be somewere in between.
</p>
<p>AIC and BIC are intended to measure different things.  Briefly,
AIC measures predictive ability, whereas BIC is expected to choose
the true model from a set of models where one of them is the
truth.  Therefore BIC chooses simpler models for all but the
tiniest sample sizes (<code class="reqn">log(n)&gt;2</code>, <code class="reqn">n&gt;7</code>).  AIC might be preferred in the
typical situation where
"all models are wrong but some are useful". AIC also gives similar
results to cross-validation (Stone 1977).
</p>


<h3>Value</h3>

<p>The BIC of the fitted model.  This is minus twice the log likelihood plus <code>p*log(n)</code>, where
<code>p</code> is the number of parameters and <code>n</code> is the sample
size of the data.  If <code>weights</code> was supplied to
<code>flexsurv</code>, the sample size is defined as the sum of the
weights.
</p>


<h3>References</h3>

<p>Kass, R. E., &amp; Raftery, A. E. (1995). Bayes
factors. Journal of the American Statistical Association,
90(430), 773-795.
</p>
<p>Stone, M. (1977). An asymptotic equivalence of choice
of model by cross‚Äêvalidation and Akaike's criterion. Journal of
the Royal Statistical Society: Series B (Methodological), 39(1),
44-47.
</p>


<h3>See Also</h3>

<p><code>BIC</code>, <code>AIC</code>, <code>AICC.flexsurvreg</code>, <code>nobs.flexsurvreg</code>
</p>


</div>