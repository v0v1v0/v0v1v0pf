<div class="container">

<table style="width: 100%;"><tr>
<td>knn.dist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k Nearest Neighbor Distances</h2>

<h3>Description</h3>

<p>Fast k-nearest neighbor distance searching algorithms.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
  knn.dist(data, k=10, algorithm=c("kd_tree", "cover_tree", "CR", "brute"))
  knnx.dist(data, query, k=10, algorithm=c("kd_tree", "cover_tree",
           "CR", "brute"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an input data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>query</code></td>
<td>
<p>a query data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>nearest neighbor searching algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the maximum number of nearest neighbors to search. The default value
is set to 10.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>return the Euclidiean distances of k nearest neighbors.
</p>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:lishengqiao@yahoo.com">lishengqiao@yahoo.com</a></p>


<h3>References</h3>

<p>Bentley J.L. (1975), “Multidimensional binary search trees used for associative
search,” <em>Communication ACM</em>, <b>18</b>, 309-517.
</p>
<p>Arya S. and Mount D.M. (1993),
“Approximate nearest neighbor searching,”
<em>Proc. 4th Ann. ACM-SIAM Symposium on Discrete Algorithms (SODA'93)</em>, 271-280.
</p>
<p>Arya S., Mount D.M., Netanyahu N.S., Silverman R. and Wu A.Y. (1998),
“An optimal algorithm for approximate nearest neighbor searching,”
<em>Journal of the ACM</em>, <b>45</b>, 891-923.
</p>
<p>Beygelzimer A., Kakade S. and Langford J. (2006),
“Cover trees for nearest neighbor,”
<em>ACM Proc. 23rd international conference on Machine learning</em>, <b>148</b>, 97-104.
</p>


<h3>See Also</h3>

<p><code>get.knn</code> and <code>knn.index</code> .
</p>


<h3>Examples</h3>

<pre><code class="language-R">  if(require(mvtnorm))
  {
    sigma&lt;- function(v, r, p)
    {
      	V&lt;- matrix(r^2, ncol=p, nrow=p)
    	  diag(V)&lt;- 1
        V*v
    }

    X&lt;- rmvnorm(1000, mean=rep(0, 20), sigma(1, .5, 20))
    print(system.time(knn.dist(X)) )
    print(system.time(knn.dist(X, algorithm = "kd_tree")))

  }
</code></pre>


</div>