<div class="container">

<table style="width: 100%;"><tr>
<td>ClusterabilityMDplot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Clusterability MDplot
</h2>

<h3>Description</h3>

<p>Clusterability mirrored-density plot. Clusterability aims to quantify the degree of cluster structures [Adolfsson et al., 2019].
A dataset has a high probabilty to possess cluster structures, if the first component of the PCA projection is multimodal [Adolfsson et al., 2019]. As the dip test is less exact than the MDplot [Thrun et al., 2020] , pvalues above 0.05 can be given for MDplots which are clearly multimodal. 
</p>
<p>An alternative investigation of clusterability can be performed by inspecting the topographic map of the Generalized U-Matrix for a specfic projection method using the <span class="pkg">ProjectionBasesdClustering</span> and <span class="pkg">GeneralizedUmatrix</span> packages on CRAN, see [Thrun/Ultsch, 2021] for details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ClusterabilityMDplot(DataOrDistance,Method,

na.rm=FALSE,PlotIt=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DataOrDistance</code></td>
<td>

<p>Either a dataset[1:n,1:d] of n cases and d features or a symmetric distance matrix [1:d,1:d] 
or multiple data sets or distances in a list
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Method</code></td>
<td>

<p>"none" performs no dimension reduction.
</p>
<p>"pca" uses the scores from the first principal component.
</p>
<p>"distance" computes pairwise distances (using distance_metric as the metric).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Statistical testing will not work with missing values, if TRUE values are imputed with averages</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PlotIt</code></td>
<td>
<p>TRUE: print plot, otherwise do not plot directly, instead use <code>Handle</code> for further adjustment</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments for function<code>MDplot4multiplevectors</code> of package <span class="pkg">DataVisualizations</span> like <code>"main"</code>, and <code>"Ordering"</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Use the method of [Adolfsson et al., 2019] specified as pca plus dip-test (PCA dip) per default without scaling or standardization of data because this step should never be done automatically. In [Thrun, 2020] the standardization and scaling did not improve the results.
</p>
<p>If list is named, than the names of the list will be used and the MDplots will be re-ordered according to multimodality in the plot, otherwise only the pvalues of [Adolfsson et al., 2019] will be the names and the ordering of the MDplots is the same as the list.
</p>
<p>Beware, as shown below, this test fails for almost touching clusters of Tetra and is difficult to intepret on WingNut but with overlayed with a roubustly estimated unimodal Gaussian distribution it can be interpreted as multimodal). However,  it does not fail for chaining data contrary to the claim in [Adolfsson et al., 2019].
</p>
<p>Based on [Thrun, 2020], the author of this function disagrees with [Adolfsson et al., 2019] as to the preference which clusterablity method should be used because the approach "distance" is not preferable for density-based cluster structures.
</p>


<h3>Value</h3>

<p>List of
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Handle</code></td>
<td>
<p>GGobject, plotter handle of <span class="pkg">ggplot2</span></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Pvalue</code></td>
<td>
<p>One or more p-values of dip test depending on <code>DataOrDistance</code></p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>"none" seems to call dip.test in clusterabilitytest with high-dimensional data. In that case dip.test just vectorizes the matrix of the data which does not make any sense. Since this could be a bug, the "none" option should not be used.
</p>
<p>Imputation does not work for distance matrices. Imputation is still experimental. It is adviced to impute missing values before using this function
</p>


<h3>Author(s)</h3>

<p>Michael Thrun
</p>


<h3>References</h3>

<p>[Adolfsson et al., 2019]  Adolfsson, A., Ackerman, M., &amp; Brownstein, N. C.: To cluster, or not to cluster: An analysis of clusterability methods, Pattern Recognition, Vol. 88, pp. 13-26. 2019.
</p>
<p>[Thrun et al., 2020]  Thrun, M. C., Gehlert, T. &amp; Ultsch, A.: Analyzing the Fine Structure of Distributions, PLoS ONE, Vol. 15(10), pp. 1-66, DOI <a href="https://doi.org/10.1371/journal.pone.0238835">doi:10.1371/journal.pone.0238835</a>, 2020. 
</p>
<p>[Thrun/Ultsch, 2021]  Thrun, M. C., and Ultsch, A.: Swarm Intelligence for Self-Organized Clustering, Artificial Intelligence, Vol. 290, pp. 103237, <a href="https://doi.org/10.1016/j.artint.2020.103237">doi:10.1016/j.artint.2020.103237</a>, 2021.
</p>
<p>[Thrun, 2020]  Thrun, M. C.: Improving the Sensitivity of Statistical Testing for Clusterability with Mirrored-Density Plot, in Archambault, D., Nabney, I. &amp; Peltonen, J. (eds.), Machine Learning Methods in Visualisation for Big Data, The Eurographics Association, <a href="https://diglib.eg.org:443/handle/10.2312/mlvis20201102">https://diglib.eg.org:443/handle/10.2312/mlvis20201102</a>, Norrkoping, Sweden, May, 2020.
</p>


<h3>See Also</h3>

<p><code>MDplot</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">##one dataset
data(Hepta)

ClusterabilityMDplot(Hepta$Data)

##multiple datasets
data(Atom)
data(Chainlink)
data(Lsun3D)
data(GolfBall)
data(EngyTime)
data(Target)
data(Tetra)
data(WingNut)
data(TwoDiamonds)

DataV = list(
  Atom = Atom$Data,
  Chainlink = Chainlink$Data,
  Hepta = Hepta$Data,
  Lsun3D = Lsun3D$Data,
  GolfBall = GolfBall$Data,
  EngyTime = EngyTime$Data,
  Target = Target$Data,
  Tetra = Tetra$Data,
  WingNut = WingNut$Data,
  TwoDiamonds = TwoDiamonds$Data
)

ClusterabilityMDplot(DataV)


</code></pre>


</div>