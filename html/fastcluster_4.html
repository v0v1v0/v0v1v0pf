<div class="container">

<table style="width: 100%;"><tr>
<td>hclust.vector</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fast hierarchical, agglomerative clustering of vector data</h2>

<h3>Description</h3>

<p>This function implements hierarchical, agglomerative clustering with memory-saving algorithms.</p>


<h3>Usage</h3>

<pre><code class="language-R">hclust.vector(X, method="single", members=NULL, metric='euclidean', p=NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>an <code class="reqn">(N\times D)</code> matrix of 'double' values:
<code class="reqn">N</code> observations in <code class="reqn">D</code> variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the agglomeration method to be used. This must be (an
unambiguous abbreviation of) one of <code>"single"</code>,
<code>"ward"</code>, <code>"centroid"</code> or <code>"median"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>members</code></td>
<td>
<p><code>NULL</code> or a vector with length the number of observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>the distance measure to be used. This must be one of
<code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>,
<code>"canberra"</code>, <code>"binary"</code> or <code>"minkowski"</code>. Any
unambiguous substring can be given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>parameter for the Minkowski metric.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>hclust.vector</code> provides clustering when the
input is vector data. It uses memory-saving algorithms which allow
processing of larger data sets than <code>hclust</code> does.
</p>
<p>The <code>"ward"</code>, <code>"centroid"</code> and <code>"median"</code> methods
require <code>metric="euclidean"</code> and cluster the data set with
respect to Euclidean distances.
</p>
<p>For <code>"single"</code> linkage clustering, any dissimilarity
measure may be chosen. Currently, the same metrics are implemented as the
<code>dist</code> function provides.
</p>
<p>The call</p>
<pre>  hclust.vector(X, method='single', metric=[...])</pre>
<p>gives the same result as</p>
<pre>  hclust(dist(X, metric=[...]), method='single')</pre>
<p>but uses less memory and is equally fast.
</p>
<p>For the Euclidean methods, care must be taken since
<code>hclust</code> expects <b>squared</b> Euclidean
distances. Hence, the call</p>
<pre>  hclust.vector(X, method='centroid')</pre>
<p>is, aside from the lesser memory requirements, equivalent to</p>
<pre>  d = dist(X)
  hc = hclust(d^2, method='centroid')
  hc$height = sqrt(hc$height)</pre>
<p>The same applies to the <code>"median"</code> method. The <code>"ward"</code> method in
<code>hclust.vector</code> is equivalent to <code>hclust</code> with method <code>"ward.D2"</code>,
but to method <code>"ward.D"</code> only after squaring as above.
</p>
<p>More details are in the User's manual
<a href="https://CRAN.R-project.org/package=fastcluster/vignettes/fastcluster.pdf">fastcluster.pdf</a>, which is available as
a vignette. Get this from the R command line with
<code>vignette('fastcluster')</code>.
</p>


<h3>Author(s)</h3>

<p>Daniel MÃ¼llner</p>


<h3>References</h3>

<p><a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a></p>


<h3>See Also</h3>

<p><code>fastcluster</code>, <code>hclust</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># Taken and modified from stats::hclust
## Perform centroid clustering with squared Euclidean distances,
## cut the tree into ten clusters and reconstruct the upper part of the
## tree from the cluster centers.
hc &lt;- hclust.vector(USArrests, "cen")
# squared Euclidean distances
hc$height &lt;- hc$height^2
memb &lt;- cutree(hc, k = 10)
cent &lt;- NULL
for(k in 1:10){
  cent &lt;- rbind(cent, colMeans(USArrests[memb == k, , drop = FALSE]))
}
hc1 &lt;- hclust.vector(cent, method = "cen", members = table(memb))
# squared Euclidean distances
hc1$height &lt;- hc1$height^2
opar &lt;- par(mfrow = c(1, 2))
plot(hc,  labels = FALSE, hang = -1, main = "Original Tree")
plot(hc1, labels = FALSE, hang = -1, main = "Re-start from 10 clusters")
par(opar)
</code></pre>


</div>