<div class="container">

<table style="width: 100%;"><tr>
<td>ShapInterpretation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>ShapInterpretation</h2>

<h3>Description</h3>

<p>Base interpereter to use the 'SHAP' interpretation library
</p>


<h3>Usage</h3>

<pre><code class="language-R">ShapInterpretation(
  learn,
  test_data = NULL,
  link = "identity",
  l1_reg = "auto",
  n_samples = 128
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>learn</code></td>
<td>
<p>learner/model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_data</code></td>
<td>
<p>should be either a Pandas dataframe or a TabularDataLoader. If not, 100 random rows of
the training data will be used instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>link</code></td>
<td>
<p>link can either be "identity" or "logit". A generalized linear model link to connect
the feature importance values to the model output. Since the feature importance values, phi, sum up
to the model output, it often makes sense to connect them to the ouput with a link function where
link(outout) = sum(phi). If the model output is a probability then the LogitLink link function makes
the feature importance values have log-odds units.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l1_reg</code></td>
<td>
<p>can be an integer value representing the number of features, "auto", "aic", "bic", or
a float value. The l1 regularization to use for feature selection (the estimation procedure is based
on a debiased lasso). The auto option currently uses "aic" when less that 20
space is enumerated, otherwise it uses no regularization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_samples</code></td>
<td>
<p>can either be "auto" or an integer value. This is the number of times to re-evaluate
the model when explaining each predictions. More samples leads to lower variance estimations of the SHAP values</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>None
</p>


</div>