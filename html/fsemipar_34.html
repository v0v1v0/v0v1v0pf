<div class="container">

<table style="width: 100%;"><tr>
<td>predict.IASSMR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Prediction for MFPLSIM
</h2>

<h3>Description</h3>

<p><code>predict</code> method for the multi-functional partial linear single-index model (MFPLSIM) fitted using <code>IASSMR.kernel.fit</code> or <code>IASSMR.kNN.fit</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
## S3 method for class 'IASSMR.kernel'
predict(object, newdata.x = NULL, newdata.z = NULL,
  y.test = NULL, option = NULL, ...)
## S3 method for class 'IASSMR.kNN'
predict(object, newdata.x = NULL, newdata.z = NULL,
  y.test = NULL, option = NULL, knearest.n = object$knearest, 
  min.knn.n = object$min.knn, max.knn.n = object$max.knn.n, 
  step.n = object$step, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>Output of the functions mentioned in the <code>Description</code> (i.e. an object of the class <code>IASSMR.kernel</code> or <code>IASSMR.kNN</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata.x</code></td>
<td>

<p>A matrix containing new observations of the functional covariate in the functional single-index component, collected by row.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata.z</code></td>
<td>

<p>Matrix containing the new observations of the scalar covariates derived from the discretisation  of a curve,  collected by row. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y.test</code></td>
<td>

<p>(optional) A vector containing the new observations of the response.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>option</code></td>
<td>

<p>Allows the choice between 1, 2 and 3. The default is 1. See the section <code>Details</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Further arguments.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knearest.n</code></td>
<td>

<p>Only used for objects <code>IASSMR.kNN</code> if <code>option=2</code> or <code>option=3</code>: vector of positive integers containing the sequence in which the  number of nearest neighbours <code>k.opt</code> is selected. The default is <code>object$knearest</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.knn.n</code></td>
<td>

<p>Only used for objects <code>IASSMR.kNN</code> if <code>option=2</code> or <code>option=3</code>: minumum value of the sequence in which the  number of neighbours <code>k.opt</code> is selected (thus, this number must be smaller than the sample size). The default is <code>object$min.knn</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.knn.n</code></td>
<td>

<p>Only used for objects <code>IASSMR.kNN</code> if <code>option=2</code> or <code>option=3</code>: maximum value of the sequence in which the number of neighbours <code>k.opt</code> is selected (thus, this number must be larger than <code>min.kNN</code> and smaller than the sample size). The default is <code>object$max.knn</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step.n</code></td>
<td>

<p>Only used for objects <code>IASSMR.kNN</code> if <code>option=2</code> or <code>option=3</code>: positive integer used to build the sequence of k-nearest neighbours as follows: <code>min.knn, min.knn + step.n, min.knn + 2*step.n, min.knn + 3*step.n,...</code>. The default is  <code>object$step</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Three options are provided to obtain the predictions of the response for <code>newdata.x</code> and <code>newdata.z</code>:
</p>

<ul>
<li>
<p> If <code>option=1</code>, we maintain all the estimates (<code>k.opt</code> or <code>h.opt</code>, <code>theta.est</code> and <code>beta.est</code>) to predict the functional single-index component of the model. As we use the estimates of the second step of the algorithm, only the <code>train.2</code> is used as training sample to predict.
Then, it should be noted that <code>k.opt</code> or <code>h.opt</code> may not be suitable to predict the functional single-index component of the model.
</p>
</li>
<li>
<p> If <code>option=2</code>, we maintain <code>theta.est</code> and <code>beta.est</code>, while the tuning parameter (<code class="reqn">h</code> or <code class="reqn">k</code>) is selected again to predict the functional single-index component of the model. This selection is performed using the leave-one-out cross-validation criterion in the functional single-index model associated and the complete training sample (i.e. <code>train=c(train.1,train.2)</code>). As we use the entire training sample (not just a subsample of it), the sample size is modified and, as a consequence,  the parameters <code>knearest</code>, <code>min.knn</code>, <code>max.knn</code>, <code>step</code> given to the function <code>IASSMR.kNN.fit</code> may need to be provided again to compute predictions. For that, we add the arguments <code>knearest.n</code>, <code>min.knn.n</code>, <code>max.knn.n</code> and <code>step.n</code>.
</p>
</li>
<li>
<p>  If <code>option=3</code>, we maintain only the indexes of the relevant variables selected by the IASSMR. We estimate again the linear coefficients and the functional index  by means of <code>sfplsim.kernel.fit</code> or <code>sfplsim.kNN.fit</code>, respectively, without penalisation (setting <code>lambda.seq=0</code>) and using the whole training sample (<code>train=c(train.1,train.2)</code>). The method provides two predictions (and MSEPs):
</p>

<ul>
<li>
<p> a) The prediction associated with <code>option=1</code> for <code>sfplsim.kernel</code> or <code>sfplsim.kNN</code> class.
</p>
</li>
<li>
<p> b) The prediction associated with <code>option=2</code> for <code>sfplsim.kernel</code> or <code>sfplsim.kNN</code> class.
</p>
</li>
</ul>
<p>(see the documentation of the functions <code>predict.sfplsim.kernel</code> and <code>predict.sfplsim.kNN</code>)
</p>
</li>
</ul>
<h3>Value</h3>

<p>The function returns the predicted values of the response (<code>y</code>) for <code>newdata.x</code> and <code>newdata.z</code>. If <code>!is.null(y.test)</code>, it also provides the mean squared error of prediction (<code>MSEP</code>) computed as <code>mean((y-y.test)^2)</code>.
If <code>option=3</code>, two sets of predictions (and two MSEPs) are provided, corresponding to the items a) and b) mentioned in the section <code>Details.</code>
If <code>is.null(newdata.x)</code> or <code>is.null(newdata.z)</code>,  the function returns the fitted values.
</p>


<h3>Author(s)</h3>

<p>German Aneiros Perez <a href="mailto:german.aneiros@udc.es">german.aneiros@udc.es</a> 
</p>
<p>Silvia Novo Diaz  <a href="mailto:snovo@est-econ.uc3m.es">snovo@est-econ.uc3m.es</a>
</p>


<h3>See Also</h3>

<p><code>sfplsim.kernel.fit</code>, <code>sfplsim.kNN.fit</code>, <code>IASSMR.kernel.fit</code>, <code>IASSMR.kNN.fit</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Sugar)

y&lt;-Sugar$ash
x&lt;-Sugar$wave.290
z&lt;-Sugar$wave.240

#Outliers
index.y.25 &lt;- y &gt; 25
index.atip &lt;- index.y.25
(1:268)[index.atip]

#Dataset to model
x.sug &lt;- x[!index.atip,]
z.sug&lt;- z[!index.atip,]
y.sug &lt;- y[!index.atip]

train&lt;-1:216
test&lt;-217:266

#Fit
fit.kernel&lt;-IASSMR.kernel.fit(x=x.sug[train,],z=z.sug[train,], y=y.sug[train],
            train.1=1:108,train.2=109:216,nknot.theta=2,lambda.min.h=0.03,
            lambda.min.l=0.03,  max.q.h=0.35,  nknot=20,criterion="BIC",
            max.iter=5000)

fit.kNN&lt;- IASSMR.kNN.fit(x=x.sug[train,],z=z.sug[train,], y=y.sug[train],
          train.1=1:108,train.2=109:216,nknot.theta=2,lambda.min.h=0.07,
          lambda.min.l=0.07, max.knn=20, nknot=20,criterion="BIC",
          max.iter=5000)

#Predictions
predict(fit.kernel,newdata.x=x.sug[test,],newdata.z=z.sug[test,],y.test=y.sug[test],option=2)
predict(fit.kNN,newdata.x=x.sug[test,],newdata.z=z.sug[test,],y.test=y.sug[test],option=2)

</code></pre>


</div>