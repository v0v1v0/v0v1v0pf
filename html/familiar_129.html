<div class="container">

<table style="width: 100%;"><tr>
<td>extract_calibration_data</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Internal function to extract calibration data.</h2>

<h3>Description</h3>

<p>Computes calibration data from a <code>familiarEnsemble</code> object.
Calibration tests are performed based on expected (predicted) and observed
outcomes. For all outcomes, calibration-at-the-large and calibration slopes
are determined. Furthermore, for all but survival outcomes, a repeated,
randomised grouping Hosmer-Lemeshow test is performed. For survival
outcomes, the Nam-D'Agostino and Greenwood-Nam-D'Agostino tests are
performed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">extract_calibration_data(
  object,
  data,
  cl = NULL,
  ensemble_method = waiver(),
  evaluation_times = waiver(),
  detail_level = waiver(),
  estimation_type = waiver(),
  aggregate_results = waiver(),
  confidence_level = waiver(),
  bootstrap_ci_method = waiver(),
  is_pre_processed = FALSE,
  message_indent = 0L,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A <code>familiarEnsemble</code> object, which is an ensemble of one or more
<code>familiarModel</code> objects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A <code>dataObject</code> object, <code>data.table</code> or <code>data.frame</code> that
constitutes the data that are assessed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>Cluster created using the <code>parallel</code> package. This cluster is then
used to speed up computation through parallellisation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ensemble_method</code></td>
<td>
<p>Method for ensembling predictions from models for the
same sample. Available methods are:
</p>

<ul>
<li> <p><code>median</code> (default): Use the median of the predicted values as the ensemble
value for a sample.
</p>
</li>
<li> <p><code>mean</code>: Use the mean of the predicted values as the ensemble value for a
sample.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>evaluation_times</code></td>
<td>
<p>One or more time points that are used for in analysis of
survival problems when data has to be assessed at a set time, e.g.
calibration. If not provided explicitly, this parameter is read from
settings used at creation of the underlying <code>familiarModel</code> objects. Only
used for <code>survival</code> outcomes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>detail_level</code></td>
<td>
<p>(<em>optional</em>) Sets the level at which results are computed
and aggregated.
</p>

<ul>
<li> <p><code>ensemble</code>: Results are computed at the ensemble level, i.e. over all
models in the ensemble. This means that, for example, bias-corrected
estimates of model performance are assessed by creating (at least) 20
bootstraps and computing the model performance of the ensemble model for
each bootstrap.
</p>
</li>
<li> <p><code>hybrid</code> (default): Results are computed at the level of models in an
ensemble. This means that, for example, bias-corrected estimates of model
performance are directly computed using the models in the ensemble. If there
are at least 20 trained models in the ensemble, performance is computed for
each model, in contrast to <code>ensemble</code> where performance is computed for the
ensemble of models. If there are less than 20 trained models in the
ensemble, bootstraps are created so that at least 20 point estimates can be
made.
</p>
</li>
<li> <p><code>model</code>: Results are computed at the model level. This means that, for
example, bias-corrected estimates of model performance are assessed by
creating (at least) 20 bootstraps and computing the performance of the model
for each bootstrap.
</p>
</li>
</ul>
<p>Note that each level of detail has a different interpretation for bootstrap
confidence intervals. For <code>ensemble</code> and <code>model</code> these are the confidence
intervals for the ensemble and an individual model, respectively. That is,
the confidence interval describes the range where an estimate produced by a
respective ensemble or model trained on a repeat of the experiment may be
found with the probability of the confidence level. For <code>hybrid</code>, it
represents the range where any single model trained on a repeat of the
experiment may be found with the probability of the confidence level. By
definition, confidence intervals obtained using <code>hybrid</code> are at least as
wide as those for <code>ensemble</code>. <code>hybrid</code> offers the correct interpretation if
the goal of the analysis is to assess the result of a single, unspecified,
model.
</p>
<p><code>hybrid</code> is generally computationally less expensive then <code>ensemble</code>, which
in turn is somewhat less expensive than <code>model</code>.
</p>
<p>A non-default <code>detail_level</code> parameter can be specified for separate
evaluation steps by providing a parameter value in a named list with data
elements, e.g. <code>list("auc_data"="ensemble", "model_performance"="hybrid")</code>.
This parameter can be set for the following data elements: <code>auc_data</code>,
<code>decision_curve_analyis</code>, <code>model_performance</code>, <code>permutation_vimp</code>,
<code>ice_data</code>, <code>prediction_data</code> and <code>confusion_matrix</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimation_type</code></td>
<td>
<p>(<em>optional</em>) Sets the type of estimation that should be
possible. This has the following options:
</p>

<ul>
<li> <p><code>point</code>: Point estimates.
</p>
</li>
<li> <p><code>bias_correction</code> or <code>bc</code>: Bias-corrected estimates. A bias-corrected
estimate is computed from (at least) 20 point estimates, and <code>familiar</code> may
bootstrap the data to create them.
</p>
</li>
<li> <p><code>bootstrap_confidence_interval</code> or <code>bci</code> (default): Bias-corrected
estimates with bootstrap confidence intervals (Efron and Hastie, 2016). The
number of point estimates required depends on the <code>confidence_level</code>
parameter, and <code>familiar</code> may bootstrap the data to create them.
</p>
</li>
</ul>
<p>As with <code>detail_level</code>, a non-default <code>estimation_type</code> parameter can be
specified for separate evaluation steps by providing a parameter value in a
named list with data elements, e.g. <code>list("auc_data"="bci", "model_performance"="point")</code>. This parameter can be set for the following
data elements: <code>auc_data</code>, <code>decision_curve_analyis</code>, <code>model_performance</code>,
<code>permutation_vimp</code>, <code>ice_data</code>, and <code>prediction_data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aggregate_results</code></td>
<td>
<p>(<em>optional</em>) Flag that signifies whether results
should be aggregated during evaluation. If <code>estimation_type</code> is
<code>bias_correction</code> or <code>bc</code>, aggregation leads to a single bias-corrected
estimate. If <code>estimation_type</code> is <code>bootstrap_confidence_interval</code> or <code>bci</code>,
aggregation leads to a single bias-corrected estimate with lower and upper
boundaries of the confidence interval. This has no effect if
<code>estimation_type</code> is <code>point</code>.
</p>
<p>The default value is equal to <code>TRUE</code> except when assessing metrics to assess
model performance, as the default violin plot requires underlying data.
</p>
<p>As with <code>detail_level</code> and <code>estimation_type</code>, a non-default
<code>aggregate_results</code> parameter can be specified for separate evaluation steps
by providing a parameter value in a named list with data elements, e.g.
<code>list("auc_data"=TRUE, , "model_performance"=FALSE)</code>. This parameter exists
for the same elements as <code>estimation_type</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>confidence_level</code></td>
<td>
<p>(<em>optional</em>) Numeric value for the level at which
confidence intervals are determined. In the case bootstraps are used to
determine the confidence intervals bootstrap estimation, <code>familiar</code> uses the
rule of thumb <code class="reqn">n = 20 / ci.level</code> to determine the number of required
bootstraps.
</p>
<p>The default value is <code>0.95</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bootstrap_ci_method</code></td>
<td>
<p>(<em>optional</em>) Method used to determine bootstrap
confidence intervals (Efron and Hastie, 2016). The following methods are
implemented:
</p>

<ul>
<li> <p><code>percentile</code> (default): Confidence intervals obtained using the percentile
method.
</p>
</li>
<li> <p><code>bc</code>: Bias-corrected confidence intervals.
</p>
</li>
</ul>
<p>Note that the standard method is not implemented because this method is
often not suitable due to non-normal distributions. The bias-corrected and
accelerated (BCa) method is not implemented yet.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_pre_processed</code></td>
<td>
<p>Flag that indicates whether the data was already
pre-processed externally, e.g. normalised and clustered. Only used if the
<code>data</code> argument is a <code>data.table</code> or <code>data.frame</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>message_indent</code></td>
<td>
<p>Number of indentation steps for messages shown during
computation and extraction of various data elements.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Flag to indicate whether feedback should be provided on the
computation and extraction of various data elements.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Unused arguments.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with data.tables containing calibration test information for
the ensemble model.
</p>


</div>