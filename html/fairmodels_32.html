<div class="container">

<table style="width: 100%;"><tr>
<td>plot.performance_and_fairness</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot fairness and performance</h2>

<h3>Description</h3>

<p>visualize fairness and model metric at the same time. Note that fairness metric parity scale is reversed so that the best models are in top right corner.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'performance_and_fairness'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>performance_and_fairness</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other plot parameters</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>ggplot</code> object
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data("german")

y_numeric &lt;- as.numeric(german$Risk) - 1

lm_model &lt;- glm(Risk ~ .,
  data = german,
  family = binomial(link = "logit")
)


explainer_lm &lt;- DALEX::explain(lm_model, data = german[, -1], y = y_numeric)

fobject &lt;- fairness_check(explainer_lm,
  protected = german$Sex,
  privileged = "male"
)

paf &lt;- performance_and_fairness(fobject)
plot(paf)


rf_model &lt;- ranger::ranger(Risk ~ .,
  data = german,
  probability = TRUE,
  num.trees = 200
)

explainer_rf &lt;- DALEX::explain(rf_model, data = german[, -1], y = y_numeric)

fobject &lt;- fairness_check(explainer_rf, fobject)

# same explainers with different cutoffs for female
fobject &lt;- fairness_check(explainer_lm, explainer_rf, fobject,
  protected = german$Sex,
  privileged = "male",
  cutoff = list(female = 0.4),
  label = c("lm_2", "rf_2")
)

paf &lt;- performance_and_fairness(fobject)

plot(paf)


</code></pre>


</div>