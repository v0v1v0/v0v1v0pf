<div class="container">

<table style="width: 100%;"><tr>
<td>plotModels.ROC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot test ROC curves of each cross-validation model</h2>

<h3>Description</h3>

<p>This function plots test ROC curves of each model found in the cross validation process.
It will also aggregate the models into a single prediction performance, plotting the resulting ROC curve (models coherence).
Furthermore, it will plot the mean sensitivity for a given set of specificities.
</p>


<h3>Usage</h3>

<pre><code class="language-R">   plotModels.ROC(modelPredictions,
    number.of.models=0,
    specificities=c(0.975,0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10,0.05),
    theCVfolds=1,
    predictor="Prediction",
	cex=1.0,
	thr=NULL,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>modelPredictions</code></td>
<td>

<p>A data frame returned by the <code>crossValidationFeatureSelection_Bin</code> function, either the <code>Models.testPrediction</code>, the <code>FullBSWiMS.testPrediction</code>,<br> the <code>Models.CVtestPredictions</code>, the <code>TestRetrained.blindPredictions</code>,<br> the <code>KNN.testPrediction</code>, or the <code>LASSO.testPredictions</code> value
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>number.of.models</code></td>
<td>

<p>The maximum number of models to plot
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>specificities</code></td>
<td>

<p>Vector containing the specificities at which the ROC sensitivities will be calculated
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theCVfolds</code></td>
<td>

<p>The number of folds performed in a Cross-validation experiment
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictor</code></td>
<td>

<p>The name of the column to be plotted
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cex</code></td>
<td>

<p>Controlling the font size of the text inside the plots
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thr</code></td>
<td>

<p>The threshold for confusion matrix
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Additional parameters for the <code>roc</code> function (<code>pROC</code> package)
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ROC.AUCs</code></td>
<td>

<p>A vector with the AUC of each ROC
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean.sensitivities</code></td>
<td>

<p>A vector with the mean sensitivity at the specificities given by <code>specificities</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model.sensitivities</code></td>
<td>

<p>A matrix where each row represents the sensitivity at the specificity given by <code>specificities</code> for a different ROC
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>specificities</code></td>
<td>

<p>The specificities used to calculate the sensitivities
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>senAUC</code></td>
<td>

<p>The AUC of the ROC curve that resulted from using <code>mean.sensitivities</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictionTable</code></td>
<td>

<p>The confusion matrix between the outcome and the ensemble prediction
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ensemblePrediction</code></td>
<td>

<p>The ensemble (median prediction) of the repeated predictions
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


</div>