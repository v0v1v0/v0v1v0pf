<div class="container">

<table style="width: 100%;"><tr>
<td>performance_and_fairness</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Performance and fairness</h2>

<h3>Description</h3>

<p>Measure performance in both fairness metric and
</p>


<h3>Usage</h3>

<pre><code class="language-R">performance_and_fairness(x, fairness_metric = NULL, performance_metric = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>object of class <code>fairness_object</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fairness_metric</code></td>
<td>
<p>fairness metric, one of metrics in fairness_objects parity_loss_metric_data  (ACC, TPR, PPV, ...) Full list in <code>fairness_check</code> documentation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>performance_metric</code></td>
<td>
<p>performance metric, one of</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Creates <code>perfomance_and_fairness</code> object. Measure model performance and model fairness metric at the same time. Choose best model according to both metrics. When plotted y axis is inversed to accentuate
that models in top right corner are the best according to both metrics.
</p>


<h3>Value</h3>

<p><code>performance_and_fairness</code> object.
It is list containing:
</p>

<ul>
<li>
<p>paf_data - performance and fairness <code>data.frame</code> containing fairness and performance metric scores for each model
</p>
</li>
<li>
<p>fairness_metric - chosen fairness metric name
</p>
</li>
<li>
<p>performance_metric - chosen performance_metric name
</p>
</li>
<li>
<p>label - model labels
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
data("german")

y_numeric &lt;- as.numeric(german$Risk) - 1

lm_model &lt;- glm(Risk ~ .,
  data = german,
  family = binomial(link = "logit")
)


explainer_lm &lt;- DALEX::explain(lm_model, data = german[, -1], y = y_numeric)

fobject &lt;- fairness_check(explainer_lm,
  protected = german$Sex,
  privileged = "male"
)

paf &lt;- performance_and_fairness(fobject)
plot(paf)


rf_model &lt;- ranger::ranger(Risk ~ .,
  data = german,
  probability = TRUE,
  num.trees = 200
)

explainer_rf &lt;- DALEX::explain(rf_model, data = german[, -1], y = y_numeric)

fobject &lt;- fairness_check(explainer_rf, fobject)

# same explainers with different cutoffs for female
fobject &lt;- fairness_check(explainer_lm, explainer_rf, fobject,
  protected = german$Sex,
  privileged = "male",
  cutoff = list(female = 0.4),
  label = c("lm_2", "rf_2")
)

paf &lt;- performance_and_fairness(fobject)

plot(paf)


</code></pre>


</div>