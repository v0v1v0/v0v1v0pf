<div class="container">

<table style="width: 100%;"><tr>
<td>classif.gsam.vs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Variable Selection in Functional Data Classification</h2>

<h3>Description</h3>

<p>Computes classification by selecting the functional (and non functional)
explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class="language-R">classif.gsam.vs(
  data = list(),
  y,
  x,
  family = binomial(),
  weights = "equal",
  basis.x = NULL,
  basis.b = NULL,
  type = "1vsall",
  prob = 0.5,
  alpha = 0.05,
  dcor.min = 0.01,
  smooth = TRUE,
  measure = "accuracy",
  xydist,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>List that containing the variables in the model.  "df" element
is a  <code>data.frame</code> with the response and scalar covariates (numeric and factors
variables are allowed). Functional covariates of class <code>fdata</code> or
<code>fd</code> are introduced in the following items in the <code>data</code> list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p><code>caracter</code> string with the name of the scalar response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>caracter</code> string vector with the name of the scalar and functional
potential covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code>family</code> for details of family functions.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li>
<p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li>
<p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>basis.b</code></td>
<td>
<p>List of basis for functional beta parameter estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p><code>character</code>, type of scheme classification. <code>'1vsall'</code>  (by default) 
strategy involves training a single classifier per class, with the samples of that class 
as positive samples and all other samples as negatives. Other posibility for K-way multiclass problem
is the <code>'majority'</code> voting scheme (also called one vs one). 
The procedure  trains the <code class="reqn">K (K - 1) / 2</code>  binary classifiers and predicts the final class label as the class
label that has been predicted most frequently.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>probability value used for binary discriminant.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>alpha value to test the null hypothesis for the test of
independence among covariate X and residual e. By default is <code>0.05</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dcor.min</code></td>
<td>
<p>lower threshold for the variable X to be considered. X is
discarded if the distance correlation <code class="reqn">R(X,e)&lt; dcor.min</code> (e is the
residual).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>if <code>TRUE</code>, a smooth estimate is made for all covariates included
in the model (less for factors). The model is adjusted with the estimated
variable linearly or smoothly. If the models are equivalent, the model is
adjusted with the linearly estimated variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>measure related with correct classification (by default accuracy).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xydist</code></td>
<td>
<p>list with the matrices of distances of each variable (all
potential covariates and the response) with itself.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Return the final fitted model (same result of the classsification method) plus:<br></p>

<ul>
<li> <p><code>dcor</code>, <code>matrix</code> with the values of distance correlation for each
pontential covariate  (by column) and the residual of the model in each step (by row).
</p>
</li>
<li> <p><code>i.predictor</code>, <code>vector</code> with 1 if the variable is selected, 0 otherwise.
</p>
</li>
<li> <p><code>ipredictor</code>, <code>vector</code> with the name of selected variables (in order of selection)
</p>
</li>
</ul>
<h3>Note</h3>

<p>Adapted version from the original method in repression: <code>fregre.gsam.vs</code>.
</p>


<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Gonz\'alez-Manteiga, W. and Oviedo de la
Fuente, M. Variable selection in functional additive regression models,
(2018).  Computational Statistics, 1-19. DOI:
<a href="https://doi.org/10.1007/s00180-018-0844-5">doi:10.1007/s00180-018-0844-5</a>
</p>


<h3>See Also</h3>

<p>See Also as:  <code>classif.gsam</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
data(tecator)
x &lt;- tecator$absorp.fdata
x1 &lt;- fdata.deriv(x)
x2 &lt;- fdata.deriv(x,nderiv=2)
y &lt;- factor(ifelse(tecator$y$Fat&lt;12,0,1))
xcat0 &lt;- cut(rnorm(length(y)),4)
xcat1 &lt;- cut(tecator$y$Protein,4)
xcat2 &lt;- cut(tecator$y$Water,4)
ind &lt;- 1:129
dat    &lt;- data.frame("Fat"=y, x1$data, xcat1, xcat2)
ldat &lt;- ldata("df"=dat[ind,],"x"=x[ind,],"x1"=x1[ind,],"x2"=x2[ind,])
# 3 functionals (x,x1,x2), 3 factors (xcat0, xcat1, xcat2)
# and 100 scalars (impact poitns of x1) 

res.gam &lt;- classif.gsam(Fat~s(x),data=ldat)
summary(res.gam)

# Time consuming
res.gam.vs &lt;- classif.gsam.vs("Fat",data=ldat)
summary(res.gam.vs)
res.gam.vs$i.predictor
res.gam.vs$ipredictor

# Prediction 
newldat &lt;- ldata("df"=dat[-ind,],"x"=x[-ind,],
                "x1"=x1[-ind,],"x2"=x2[-ind,])
pred.gam &lt;- predict(res.gam,newldat)                
pred.gam.vs &lt;- predict(res.gam.vs,newldat)
cat2meas(newldat$df$Fat, pred.gam)
cat2meas(newldat$df$Fat, pred.gam.vs)

## End(Not run)
</code></pre>


</div>