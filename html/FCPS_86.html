<div class="container">

<table style="width: 100%;"><tr>
<td>SparseClustering</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Sparse Clustering
</h2>

<h3>Description</h3>

<p>Implements the sparse clustering methods of [Witten/Tibshirani, 2010].
</p>


<h3>Usage</h3>

<pre><code class="language-R">SparseClustering(DataOrDistances, ClusterNo, Type="Hierarchical",

PlotIt=F,Silent=FALSE, NoPerms=10,Wbounds, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DataOrDistances</code></td>
<td>
<p>Either a [1:n,1:d] matrix of dataset to be clustered. It consists of n cases of d-dimensional data points. Every case has d attributes, variables or features.
</p>
<p>or a [1:n,1:n] symmetric distance matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ClusterNo</code></td>
<td>
<p>Numeric indicating number to cluster to find in Tree/
Dendrogramm in case of Type="Hierachical" or numer of cluster to use in
Type="kmeans"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Type</code></td>
<td>
<p>(optional) Char selecting methods Hierarchical or kmeans.
Default: "Hierarchical"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PlotIt</code></td>
<td>
<p>(optional) Boolean. Default = FALSE = No plotting performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Silent</code></td>
<td>
<p>(optional) Boolean: print output or not (Default = FALSE = no
output)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NoPerms</code></td>
<td>
<p>(optional), numeric scalar, Number of permutations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Wbounds</code></td>
<td>
<p>(optional) numeric vector, range of tuning parameters to consider. This is the L1 bound on w, the feature weights [Witten/Tibshirani, 2010].</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed on to sparcl HierarchicalSparseCluster or KMeansSparseCluster depending on <code>Type</code>.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List of
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Cls</code></td>
<td>
<p>[1:n]  numerical vector with n numbers defining the classification as the main output of the clustering algorithm. It has k unique numbers representing the arbitrary labels of the clustering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Object</code></td>
<td>
<p>Object defined by clustering algorithm as the other output of this algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Tree</code></td>
<td>
<p>Object Tree if Type="Hierachical" is used.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Quality of clustering results varies between sparse hierarchical if data is given in comparison to the case that distances are given.</p>


<h3>Author(s)</h3>

<p>Quirin Stier, Michael Thrun
</p>


<h3>References</h3>

<p>[Witten/Tibshirani, 2010] Witten, D. and Tibshirani, R.: A Framework for
Feature Selection in Clustering. Journal of the American Statistical
Association, Vol. 105(490), pp. 713-726, 2010.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Hepta
data("Hepta")
Data = Hepta$Data
V1 = SparseClustering(Data, ClusterNo=7, Type="kmeans")
Cls1 = V1$Cls

V2 = SparseClustering(Data, ClusterNo=7, Type="Hierarchical")
Cls2 = V2$Cls

InputDistances = parallelDist::parDist(Data, method="euclidean")
DistanceMatrix = as.matrix(InputDistances)
V3 = SparseClustering(DistanceMatrix, ClusterNo=7, Type="Hierarchical")
Cls3 = V3$Cls

## Not run: 
set.seed(1)
Data = matrix(rnorm(100*50),ncol=50)
y    = c(rep(1,50),rep(2,50))
Data[y==1,1:25] = Data[y==1,1:25]+2

V1 = SparseClustering(Data, ClusterNo=2, Type="kmeans")
Cls1 = V1$Cls

## End(Not run)

</code></pre>


</div>