<div class="container">

<table style="width: 100%;"><tr>
<td>BERT_vocab</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Check if mask words are in the model vocabulary.</h2>

<h3>Description</h3>

<p>Check if mask words are in the model vocabulary.
</p>


<h3>Usage</h3>

<pre><code class="language-R">BERT_vocab(
  models,
  mask.words,
  add.tokens = FALSE,
  add.method = c("sum", "mean")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>models</code></td>
<td>
<p>Model names at
<a href="https://huggingface.co/models?pipeline_tag=fill-mask&amp;library=transformers">HuggingFace</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mask.words</code></td>
<td>
<p>Option words filling in the mask.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add.tokens</code></td>
<td>
<p>Add new tokens (for out-of-vocabulary words or even phrases) to model vocabulary?
Defaults to <code>FALSE</code>. It only temporarily adds tokens for tasks but does not change the raw model file.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add.method</code></td>
<td>
<p>Method used to produce the token embeddings of new added tokens.
Can be <code>"sum"</code> (default) or <code>"mean"</code> of subword token embeddings.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A data.table of model name, mask word, real token (replaced if out of vocabulary),
and token id (0~N).
</p>


<h3>See Also</h3>

<p><code>BERT_download</code>
</p>
<p><code>BERT_info</code>
</p>
<p><code>FMAT_run</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
models = c("bert-base-uncased", "bert-base-cased")
BERT_info(models)

BERT_vocab(models, c("bruce", "Bruce"))

BERT_vocab(models, 2020:2025)  # some are out-of-vocabulary
BERT_vocab(models, 2020:2025, add.tokens=TRUE)  # add vocab

BERT_vocab(models,
           c("individualism", "artificial intelligence"),
           add.tokens=TRUE)

## End(Not run)

</code></pre>


</div>