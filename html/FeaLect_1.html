<div class="container">

<table style="width: 100%;"><tr>
<td>FeaLect-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Scores Features for Feature Selection
</h2>

<h3>Description</h3>


<p>Suppose you have a feature matrix with 200 features and only 20 samples and your goal is to build a classifier. 
You can run the FeaLect() function to compute the scores for your features. Only the relatively high score 
features (say the top 20) are recommended for further analysis. In this way, one can prevent overfitting by
reducing the number of features significantly. 
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> FeaLect</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Title: </td>
<td style="text-align: left;"> Scores Features for Feature Selection</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 1.20</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2020-02-25</td>
</tr>
<tr>
<td style="text-align: left;">
Author: </td>
<td style="text-align: left;"> Habil Zare</td>
</tr>
<tr>
<td style="text-align: left;">
Maintainer: </td>
<td style="text-align: left;"> Habil Zare &lt;zare@u.washington.edu&gt;</td>
</tr>
<tr>
<td style="text-align: left;">
Depends: </td>
<td style="text-align: left;"> lars, rms</td>
</tr>
<tr>
<td style="text-align: left;">
Description: </td>
<td style="text-align: left;"> For each feature, a score is computed that can be useful
        for feature selection. Several random subsets are sampled from
        the input data and for each random subset, various linear
        models are fitted using lars method. A score is assigned to
        each feature based on the tendency of LASSO in including that
        feature in the models.Finally, the average score and the models
        are returned as the output. The features with relatively low
        scores are recommended to be ignored because they can lead to
        overfitting of the model to the training data. Moreover, for
        each random subset, the best set of features in terms of global
        error is returned. They are useful for applying Bolasso, the
        alternative feature selection method that recommends the
        intersection of features subsets.</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
<td style="text-align: left;">
LazyLoad: </td>
<td style="text-align: left;"> yes</td>
</tr>
<tr>
<td style="text-align: left;">
Repository: </td>
<td style="text-align: left;"> CRAN</td>
</tr>
<tr>
<td style="text-align: left;">
Date/Publication: </td>
<td style="text-align: left;"> 2018-06-01 13:13:46 UTC</td>
</tr>
<tr>
<td style="text-align: left;">
Packaged: </td>
<td style="text-align: left;"> 2018-06-01 00:07:37 UTC; habil</td>
</tr>
<tr>
<td style="text-align: left;">
NeedsCompilation: </td>
<td style="text-align: left;"> no</td>
</tr>
<tr>
<td style="text-align: left;">
RoxygenNote: </td>
<td style="text-align: left;"> 6.0.1</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>Index of help topics:
</p>
<pre>
FeaLect                 Computes the scores of the features.
FeaLect-package         Scores Features for Feature Selection
compute.balanced        Balances between negative and positive samples
                        by oversampling.
compute.logistic.score
                        Fits a logistic regression model using the
                        linear scores
doctor.validate         Validates a model using validating samples.
ignore.redundant        Refines a feature matrix
input.check.FeaLect     Checks the inputs to Fealect() function.
mcl_sll                 MCL and SLL lymphoma subtypes
random.subset           Selects a random subset of the input.
train.doctor            Fits various models based on a combination on
                        penalized linear models and logistic
                        regression.
</pre>


<h3>Author(s)</h3>

<p>Habil Zare
</p>
<p>Maintainer: Habil Zare &lt;zare@u.washington.edu&gt;
</p>


<h3>References</h3>

<p>Zare, Habil, et al. "Scoring relevancy of features based on combinatorial analysis of Lasso with application to lymphoma diagnosis." <em>BMC genomics</em>. Vol. 14. No. 1. BioMed Central, 2013.</p>


<h3>See Also</h3>

<p><code>FeaLect</code>, <code>train.doctor</code>, <code>doctor.validate</code>, 
<code>random.subset</code>, <code>compute.balanced</code>,<code>compute.logistic.score</code>, 
<code>ignore.redundant</code>, <code>input.check.FeaLect</code>,
<code>lars-package</code>, and <code>SparseLearner-package</code>

</p>


<h3>Examples</h3>

<pre><code class="language-R">library(FeaLect)
data(mcl_sll)
F &lt;- as.matrix(mcl_sll[ ,-1])	# The Feature matrix
L &lt;- as.numeric(mcl_sll[ ,1])	# The labels
names(L) &lt;- rownames(F)
message(dim(F)[1], " samples and ",dim(F)[2], " features.")

## For this data, total.num.of.models is suggested to be at least 100.
FeaLect.result.1 &lt;-FeaLect(F=F,L=L,maximum.features.num=10,total.num.of.models=20,talk=TRUE)
</code></pre>


</div>