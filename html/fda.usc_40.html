<div class="container">

<table style="width: 100%;"><tr>
<td>classif.ML</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Functional classification using ML algotithms</h2>

<h3>Description</h3>

<p>Computes functional classification using functional (and non functional)
explanatory variables by rpart, nnet, svm or random forest model
</p>


<h3>Usage</h3>

<pre><code class="language-R">classif.nnet(formula, data, basis.x = NULL, weights = "equal", size, ...)

classif.rpart(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.svm(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.ksvm(formula, data, basis.x = NULL, weights = "equal", ...)

classif.randomForest(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.lda(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.qda(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.naiveBayes(formula, data, basis.x = NULL, laplace = 0, ...)

classif.cv.glmnet(formula, data, basis.x = NULL, weights = "equal", ...)

classif.gbm(formula, data, basis.x = NULL, weights = "equal", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li>
<p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li>
<p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>number of units in the hidden layer. Can be zero if there are skip-layer units.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>If type is<code>"1vsall"</code>  (by default) 
a maximum probability scheme is applied: requires G binary classifiers.
If type is <code>"majority"</code>  (only for multicalss classification G &gt; 2) 
a voting scheme is applied: requires  G (G - 1) / 2 binary classifiers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>laplace</code></td>
<td>
<p>value used for Laplace smoothing (additive smoothing). Defaults to 0 (no Laplace smoothing).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The first item in the <code>data</code> list is called <em>"df"</em> and is a data
frame with the response and non functional explanatory variables, as
<code>glm</code>.<br></p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items in the <code>data</code> list.<br><code>basis.x</code> is a list of
basis for represent each functional covariate. The b object can be
created by the function: <code>create.pc.basis</code>, <code>pca.fd</code>
<code>create.pc.basis</code>, <code>create.fdata.basis</code> o
<code>create.basis</code>.<br><code>basis.b</code> is a list of basis for
represent each functional beta parameter. If <code>basis.x</code> is a list of
functional principal components basis (see <code>create.pc.basis</code> or
<code>pca.fd</code>) the argument <code>basis.b</code> is ignored.
</p>


<h3>Value</h3>

<p>Return <code>classif</code> object plus:
</p>

<ul>
<li> <p><code>formula</code> formula.
</p>
</li>
<li> <p><code>data</code> List that containing the variables in the model. 
</p>
</li>
<li> <p><code>group</code> Factor of length <em>n</em> 
</p>
</li>
<li> <p><code>group.est</code> Estimated vector groups
</p>
</li>
<li> <p><code>prob.classification</code> Probability of correct classification by group.
</p>
</li>
<li> <p><code>prob.group</code> Matrix of predicted class probabilities. For each
functional point shows the probability of each possible group membership.
</p>
</li>
<li> <p><code>max.prob</code> Highest probability of correct classification.
</p>
</li>
<li> <p><code>type</code>  Type of classification scheme: 1 vs all  or majority voting.
</p>
</li>
<li> <p><code>fit</code> list of binary classification fitted models.
</p>
</li>
</ul>
<h3>Note</h3>

<p>Wrapper versions for multivariate and functional classification:
</p>

<ul>
<li> <p><code>classif.lda</code>,<code>classif.qda</code>: uses <code>lda</code> and  <code>qda</code> functions and requires <code>MASS</code> package.
</p>
</li>
<li> <p><code>classif.nnet</code>: uses <code>nnet</code> function and requires <code>nnet</code> package.
</p>
</li>
<li> <p><code>classif.rpart</code>: uses <code>nnet</code> function and requires <code>rpart</code> package.
</p>
</li>
<li> <p><code>classif.svm</code>,<code>classif.naiveBayes</code>: uses <code>svm</code> and  <code>naiveBayes</code> functions and requires <code>e1071</code> package.
</p>
</li>
<li> <p><code>classif.ksvm</code>: uses <code>weighted.ksvm </code> function and requires <code>personalized</code> package.
</p>
</li>
<li> <p><code>classif.randomForest</code>: uses <code>randomForest</code> function and requires <code>randomForest</code> package.
</p>
</li>
<li> <p><code>classif.cv.glmnet</code>: uses <code>cv.glmnet</code> function and requires <code>glmnet</code> package.
</p>
</li>
<li> <p><code>classif.gbm</code>: uses <code>gbm</code> function and requires <code>gbm</code> package.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), 
<em>Functional Data Analysis</em>, 2nd ed., Springer, New York. 
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed. Chapman and Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.  
Regression for R. R News 1(2):20-25
</p>


<h3>See Also</h3>

<p>See Also as: <code>rpart</code>.<br> Alternative method:
<code>classif.np</code>, <code>classif.glm</code>,
<code>classif.gsam</code> and <code>classif.gkam</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
data(phoneme)
mlearn&lt;-phoneme[["learn"]]
glearn&lt;-phoneme[["classlearn"]]
mtest&lt;-phoneme[["test"]]
gtest&lt;-phoneme[["classtest"]]
dataf&lt;-data.frame(glearn)
dat=ldata("df"=dataf,"x"=mlearn)
a1&lt;-classif.rpart(glearn~x,data=dat)
a2&lt;-classif.nnet(glearn~x,data=dat)
a3&lt;-classif.gbm(glearn~x,data=dat)
a4&lt;-classif.randomForest(glearn~x,data=dat)
a5&lt;-classif.cv.glmnet(glearn~x,data=dat)
newdat&lt;-list("x"=mtest)
p1&lt;-predict(a1,newdat,type="class")
p2&lt;-predict(a2,newdat,type="class")
p3&lt;-predict(a3,newdat,type="class")
p4&lt;-predict(a4,newdat,type="class")
p5&lt;-predict(a5,newdat,type="class")
mean(p1==gtest);mean(p2==gtest);mean(p3==gtest)
mean(p4==gtest);mean(p5==gtest)

## End(Not run)

</code></pre>


</div>