<div class="container">

<table style="width: 100%;"><tr>
<td>knn.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k-Nearest Neighbour Classification Cross-Validation</h2>

<h3>Description</h3>

<p>k-nearest neighbour classification cross-validation from training set.</p>


<h3>Usage</h3>

<pre><code class="language-R">knn.cv(train, cl, k = 1, prob = FALSE, algorithm=c("kd_tree",
       "cover_tree", "brute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>matrix or data frame of training set cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>factor of true classifications of training set</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of neighbours considered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>if this is true, the proportion of the votes for the winning class
are returned as attribute <code>prob</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>nearest neighbor search algorithm.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This uses leave-one-out cross validation.
For each row of the training set <code>train</code>, the <code>k</code> nearest
(in Euclidean distance) other training set vectors are found, and the classification 
is decided by majority vote, with ties broken at random. If there are ties for the
<code>k</code>th nearest vector, all candidates are included in the vote.
</p>


<h3>Value</h3>

<p>factor of classifications of training set. <code>doubt</code> will be returned as <code>NA</code>.
distances and indice of k nearest neighbors are also returned as attributes.
</p>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:lishengqiao@yahoo.com">lishengqiao@yahoo.com</a></p>


<h3>References</h3>

<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks.</em> Cambridge.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code>knn</code> and <code>knn.cv</code> in <span class="pkg">class</span>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  data(iris3)
  train &lt;- rbind(iris3[,,1], iris3[,,2], iris3[,,3])
  cl &lt;- factor(c(rep("s",50), rep("c",50), rep("v",50)))
  knn.cv(train, cl, k = 3, prob = TRUE)
  attributes(.Last.value)
</code></pre>


</div>