<div class="container">

<table style="width: 100%;"><tr>
<td>crossentropy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross Entropy</h2>

<h3>Description</h3>

<p>KNN Cross Entropy Estimators.</p>


<h3>Usage</h3>

<pre><code class="language-R">  crossentropy(X, Y, k=10, algorithm=c("kd_tree", "cover_tree", "brute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>an input data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>an input data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the maximum number of nearest neighbors to search. The default value is set to 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>nearest neighbor search algorithm.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>p(x)</code> and <code>q(x)</code> are two continuous probability density functions,
then the cross-entropy of <code>p</code> and <code>q</code> is defined as
<code class="reqn">H(p;q) = E_p[-\log q(x)]</code>.
</p>


<h3>Value</h3>

<p>a vector of length <code>k</code> for crossentropy estimates using <code>1:k</code> nearest neighbors, respectively.
</p>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:lishengqiao@yahoo.com">lishengqiao@yahoo.com</a></p>


<h3>References</h3>

<p>S. Boltz, E. Debreuve and M. Barlaud (2007).
“kNN-based high-dimensional Kullback-Leibler distance for tracking”.
<em>Image Analysis for Multimedia Interactive Services, 2007. WIAMIS '07. Eighth International Workshop on</em>.
</p>


</div>