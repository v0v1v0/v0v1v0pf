<div class="container">

<table style="width: 100%;"><tr>
<td>cocktail</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fits the regularization paths for the elastic net penalized Cox's model</h2>

<h3>Description</h3>

<p>Fits a regularization path for the elastic net penalized Cox's model at a sequence of regularization parameters lambda.</p>


<h3>Usage</h3>

<pre><code class="language-R">cocktail(x,y,d,
	nlambda=100,
	lambda.min=ifelse(nobs&lt;nvars,1e-2,1e-4),
	lambda=NULL, 
	alpha=1,
	pf=rep(1,nvars),
	exclude,
	dfmax=nvars+1,
	pmax=min(dfmax*1.2,nvars),
	standardize=TRUE,
	eps=1e-6,
	maxit=3e4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix of predictors, of dimension <code class="reqn">N \times p</code>; each row is an observation vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a survival time for Cox models. Currently tied failure times are not supported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>censor status with 1 if died and 0 if right censored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>the number of <code>lambda</code> values - default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>
<p>given as a fraction of <code>lambda.max</code> - the smallest value of <code>lambda</code> for which all coefficients are zero. The default depends on the relationship between <code class="reqn">N</code> (the number of rows in the matrix of predictors) and <code class="reqn">p</code> (the number of predictors). If <code class="reqn">N &gt; p</code>, the default is <code>0.0001</code>,
close to zero.  If <code class="reqn">N&lt;p</code>, the default is <code>0.01</code>.
A very small value of <code>lambda.min</code> will lead to a saturated fit. It takes no effect if there is user-defined <code>lambda</code> sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>a user supplied <code>lambda</code> sequence. Typically, by leaving this option unspecified users can have 
the program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.min</code>. Supplying a value of
<code>lambda</code> overrides this. It is better to supply
a decreasing sequence of <code>lambda</code> values than a single (small) value, if not, the program will sort user-defined <code>lambda</code> sequence in decreasing order automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 &lt; \alpha &lt;= 1</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pf</code></td>
<td>
<p>separate penalty weights can be applied to each coefficient of <code class="reqn">\beta</code> to allow
differential shrinkage. Can be 0 for some variables, which implies
no shrinkage, and results in that variable always being included in the
model. Default is 1 for all variables (and implicitly infinity for
variables listed in <code>exclude</code>). See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exclude</code></td>
<td>
<p>indices of variables to be excluded from the
model. Default is none. Equivalent to an infinite penalty factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dfmax</code></td>
<td>
<p>limit the maximum number of variables in the
model. Useful for very large <code class="reqn">p</code>, if a partial path is desired. Default is <code class="reqn">p+1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pmax</code></td>
<td>
<p>limit the maximum number of variables ever to be nonzero. For example once <code class="reqn">\beta</code> enters the model, no matter how many times it exits or re-enters model through the path, it will be counted only once. Default is <code>min(dfmax*1.2,p)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>logical flag for variable standardization, prior to
fitting the model sequence. If <code>TRUE</code>, x matrix is normalized such that sum squares of each column <code class="reqn">\sum^N_{i=1}x_{ij}^2/N=1</code>. Note that x is always centered (i.e. <code class="reqn">\sum^N_{i=1}x_{ij}=0</code>) no matter <code>standardize</code> is <code>TRUE</code> or <code>FALSE</code>. The coefficients are always returned on
the original scale. Default is is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>convergence threshold for coordinate majorization descent. Each inner
coordinate majorization descent loop continues until the relative change in any
coefficient (i.e. <code class="reqn">\max_j|\beta_j^{new}-\beta_j^{old}|^2</code>) is less than <code>eps</code>. Defaults value is <code>1e-6</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>maximum number of outer-loop iterations allowed at fixed lambda value. Default is 1e4. If models do not converge, consider increasing <code>maxit</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The algorithm estimates <code class="reqn">\beta</code> based on observed data, through elastic net penalized log partial likelihood of Cox's model.
</p>
<p style="text-align: center;"><code class="reqn">\arg\min(-loglik(Data,\beta)+\lambda*P(\beta))</code>
</p>

<p>It can compute estimates at a fine grid of values of <code class="reqn">\lambda</code>s in order to pick up a data-driven optimal <code class="reqn">\lambda</code> for fitting a 'best' final model. The penalty is a combination of l1 and l2 penalty:
</p>
<p style="text-align: center;"><code class="reqn">P(\beta)=(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>
 
<p><code>alpha=1</code> is the lasso penalty.
For computing speed reason, if models are not converging or running slow, consider increasing <code>eps</code>, decreasing
<code>nlambda</code>, or increasing <code>lambda.min</code> before increasing
<code>maxit</code>.
</p>
<p><strong>FAQ:</strong>
</p>
<p><b>Question: </b>“<em>I am not sure how are we optimizing alpha. I can get optimal lambda for each value of alpha. But how do I select optimum alpha?</em>” 
</p>
<p><b>Answer: </b> <code>cv.cocktail</code> only finds the optimal lambda given alpha fixed. So to
chose a good alpha you need to fit CV on a grid of alpha, say (0.1,0.3, 0.6, 0.9, 1) and let cv.cocktail choose the optimal lambda for each alpha, then you choose the (alpha, lambda) pair that corresponds to the lowest predicted deviance.
</p>
<p><b>Question: </b>“<em>I understand your are referring to minimizing the quantity <code>cv.cocktail\$cvm</code>, the mean 'cross-validated error' to optimize alpha and lambda as you did in your implementation. However, I don't know what the equation of this error is and this error is not referred to in your paper either. Do you mind explaining what this is?
</em>”
</p>
<p><b>Answer: </b> We first define the log partial-likelihood for the Cox model. Assume
<code class="reqn">\hat{\beta}^{[k]}</code> is the estimate fitted on <code class="reqn">k</code>-th fold, define the log partial likelihood function as 
</p>
<p style="text-align: center;"><code class="reqn">
L(Data,\hat{\beta}[k])=\sum_{s=1}^{S} x_{i_{s}}^{T}\hat{\beta}[k]-\log(\sum_{i\in R_{s}}\exp(x_{i}^{T}\hat{\beta}[k])).
</code>
</p>

<p>Then the log partial-likelihood deviance of the <code class="reqn">k</code>-th fold is defined
as
</p>
<p style="text-align: center;"><code class="reqn">
D[Data,k]=-2(L(Data,\hat{\beta}[k])).
</code>
</p>

<p>We now define the measurement we actually use for cross validation:
it is the difference between the log partial-likelihood deviance evaluated
on the full dataset and that evaluated on the on the dataset with
<code class="reqn">k</code>-th fold excluded. The cross-validated error is defined as
</p>
<p style="text-align: center;"><code class="reqn">
CV-ERR[k]=D(Data[full],k)-D(Data[k^{th}\,\,fold\,\,excluded],k).
</code>
</p>



<h3>Value</h3>

<p>An object with S3 class <code>cocktail</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>a <code class="reqn">p*length(lambda)</code> matrix of coefficients, stored as a sparse matrix (<code>dgCMatrix</code> class, the standard class for sparse numeric matrices in the <code>Matrix</code> package.). To convert it into normal type matrix use <code>as.matrix()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the actual sequence of <code>lambda</code> values used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>the number of nonzero coefficients for each value of
<code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>dimension of coefficient matrix (ices)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npasses</code></td>
<td>
<p>total number of iterations (the most inner loop) summed over all lambda values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jerr</code></td>
<td>
<p>error flag, for warnings and errors, 0 if no error.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yi Yang and Hui Zou<br>
Maintainer: Yi Yang  &lt;yi.yang6@mcgill.ca&gt;</p>


<h3>References</h3>

<p>Yang, Y. and Zou, H. (2013), 
"A Cocktail Algorithm for Solving The Elastic Net Penalized Cox's Regression in High Dimensions", <em>Statistics and Its Interface,</em> 6:2, 167-173.<br><a href="https://github.com/emeryyi/fastcox">https://github.com/emeryyi/fastcox</a><br></p>


<h3>See Also</h3>

<p><code>plot.cocktail</code></p>


<h3>Examples</h3>

<pre><code class="language-R">data(FHT)
m1&lt;-cocktail(x=FHT$x,y=FHT$y,d=FHT$status,alpha=0.5)
predict(m1,type="nonzero")
plot(m1)
</code></pre>


</div>