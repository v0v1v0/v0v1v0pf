<div class="container">

<table style="width: 100%;"><tr>
<td>MinimalEnergyClustering</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Minimal Energy Clustering 
</h2>

<h3>Description</h3>

<p>Hierchical Clustering using the minimal energy approach of [Szekely/Rizzo, 2005].
</p>


<h3>Usage</h3>

<pre><code class="language-R">MinimalEnergyClustering(DataOrDistances, ClusterNo = 0,
DistanceMethod="euclidean", ColorTreshold = 0,Data,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DataOrDistances</code></td>
<td>
<p>[1:n,1:d] matrix of dataset to be clustered. It consists of n cases of d-dimensional data points. Every case has d attributes, variables or features. Alternatively, symmetric [1:n,1:n] distance matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ClusterNo</code></td>
<td>
<p>A number k which defines k different clusters to be build by the algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DistanceMethod</code></td>
<td>
<p>See  <code>parDist</code>, for example 'euclidean','mahalanobis','manhatten' (cityblock),'fJaccard','binary', 'canberra', 'maximum'. Any unambiguous substring can be given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ColorTreshold</code></td>
<td>
<p>Draws cutline w.r.t. dendogram y-axis (height), height of line as scalar should be given</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Data</code></td>
<td>
<p>[1:n,1:d] data matrix in the case that <code>DataOrDistances</code> is missing and partial matching does not work.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>In case of plotting further argument for <code>plot</code>, see <code>as.dendrogram</code>
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List of
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Cls</code></td>
<td>
<p>If ClusterNo&gt;0: [1:n]  numerical vector with n numbers defining the classification as the main output of the clustering algorithm. It has k unique numbers representing the arbitrary labels of the clustering. Otherwise ClusterNo=0: NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Dendrogram</code></td>
<td>
<p>Dendrogram of hierarchical clustering algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Object</code></td>
<td>
<p>Ultrametric tree of hierarchical clustering algorithm</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michael Thrun
</p>


<h3>References</h3>

<p>[Szekely/Rizzo, 2005]  Szekely, G. J. and Rizzo, M. L.: Hierarchical Clustering via Joint Between-Within Distances: Extending Ward's Minimum Variance Method, Journal of Classification, 22(2) 151-183.http://dx.doi.org/10.1007/s00357-005-0012-9, 2005.
</p>


<h3>See Also</h3>

<p><code>HierarchicalClustering</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data('Hepta')
out=MinimalEnergyClustering(Hepta$Data,ClusterNo=7)
</code></pre>


</div>