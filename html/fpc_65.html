<div class="container">

<table style="width: 100%;"><tr>
<td>kmeansruns</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k-means with estimating k and initialisations</h2>

<h3>Description</h3>

<p>This calls the function <code>kmeans</code> to perform a k-means
clustering, but initializes the k-means algorithm several times with
random points from the data set as means. Furthermore, it is more
robust against the occurrence of empty clusters in the algorithm and
it estimates the number of clusters by either the Calinski Harabasz
index (<code>calinhara</code>) or average silhouette width (see
<code>pam.object</code>). The Duda-Hart test
(<code>dudahart2</code>) is applied to decide whether there should be
more than one cluster (unless 1 is excluded as number of clusters).
</p>


<h3>Usage</h3>

<pre><code class="language-R">kmeansruns(data,krange=2:10,criterion="ch",
                       iter.max=100,runs=100,
                       scaledata=FALSE,alpha=0.001,
                       critout=FALSE,plot=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A numeric matrix of data, or an object that can be coerced to
such a matrix (such as a numeric vector or a data frame with
all numeric columns). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>krange</code></td>
<td>
<p>integer vector. Numbers of clusters which are to be
compared by the average silhouette width criterion. Note: average
silhouette width and Calinski-Harabasz can't estimate number of
clusters <code>nc=1</code>. If 1 is included, a Duda-Hart test is applied
and 1 is estimated if this is not significant.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>one of <code>"asw"</code> or <code>"ch"</code>. Determines
whether average silhouette width or Calinski-Harabasz is applied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter.max</code></td>
<td>
<p>integer. The maximum number of iterations allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runs</code></td>
<td>
<p>integer. Number of starts of the k-means algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaledata</code></td>
<td>
<p>logical. If <code>TRUE</code>, the variables are centered
and scaled to unit variance before execution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>numeric between 0 and 1, tuning constant for
<code>dudahart2</code> (only used for 1-cluster test).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>critout</code></td>
<td>
<p>logical. If <code>TRUE</code>, the criterion value is printed
out for every number of clusters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, every clustering resulting from a
run of the algorithm is plotted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments to be passed on to <code>kmeans</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The output of the optimal run of the <code>kmeans</code>-function
with added components <code>bestk</code> and <code>crit</code>.
A list with components
</p>
<table>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>A vector of integers indicating the cluster to which each
point is allocated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>A matrix of cluster centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>withinss</code></td>
<td>
<p>The within-cluster sum of squares for each cluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>The number of points in each cluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bestk</code></td>
<td>
<p>The optimal number of clusters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>crit</code></td>
<td>
<p>Vector with values of the <code>criterion</code> for all used numbers of
clusters (0 if number not tried).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Christian Hennig
<a href="mailto:christian.hennig@unibo.it">christian.hennig@unibo.it</a>
<a href="https://www.unibo.it/sitoweb/christian.hennig/en/">https://www.unibo.it/sitoweb/christian.hennig/en/</a>
</p>


<h3>References</h3>

<p>Calinski, T., and Harabasz, J. (1974) A Dendrite Method for Cluster 
Analysis, <em>Communications in Statistics</em>, 3, 1-27.
</p>
<p>Duda, R. O. and Hart, P. E. (1973) <em>Pattern Classification and
Scene Analysis</em>. Wiley, New York.
</p>
<p>Hartigan, J. A. and Wong, M. A. (1979).  A K-means clustering
algorithm. <em>Applied Statistics</em>, 28, 100-108.
</p>
<p>Kaufman, L. and Rousseeuw, P.J. (1990). "Finding Groups in Data:
An Introduction to Cluster Analysis". Wiley, New York.
</p>


<h3>See Also</h3>

<p><code>kmeans</code>, <code>pamk</code>,
<code>calinhara</code>, <code>dudahart2</code>)  
</p>


<h3>Examples</h3>

<pre><code class="language-R">  options(digits=3)
  set.seed(20000)
  face &lt;- rFace(50,dMoNo=2,dNoEy=0,p=2)
  pka &lt;- kmeansruns(face,krange=1:5,critout=TRUE,runs=2,criterion="asw")
  pkc &lt;- kmeansruns(face,krange=1:5,critout=TRUE,runs=2,criterion="ch")
</code></pre>


</div>