<div class="container">

<table style="width: 100%;"><tr>
<td>predict.mfplm.PVS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Prediction for MFPLM
</h2>

<h3>Description</h3>

<p><code>predict</code> method for the multi-functional partial linear model (MFPLM) fitted using <code>PVS.kernel.fit</code> or <code>PVS.kNN.fit</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'PVS.kernel'
predict(object, newdata.x = NULL, newdata.z = NULL,
  y.test = NULL, option = NULL, ...)
## S3 method for class 'PVS.kNN'
predict(object, newdata.x = NULL, newdata.z = NULL, 
  y.test = NULL, option = NULL, knearest.n = object$knearest, 
  min.knn.n = object$min.knn, max.knn.n = object$max.knn.n, 
  step.n = object$step, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>Output of the functions mentioned in the <code>Description</code> (i.e. an object of the class <code>PVS.kernel</code> or <code>PVS.kNN</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata.x</code></td>
<td>

<p>A matrix containing new observations of the functional covariate in the functional nonparametric component, collected by row.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata.z</code></td>
<td>

<p>Matrix containing the new observations of the scalar covariates derived from the discretisation  of a curve,  collected by row. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y.test</code></td>
<td>

<p>(optional) A vector containing the new observations of the response.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>option</code></td>
<td>

<p>Allows the selection among the choices 1, 2 and 3 for <code>PVS.kernel</code> objects, and  1, 2, 3, and 4 for <code>PVS.kNN</code> objects. The default setting is 1. See the section <code>Details</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Further arguments.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knearest.n</code></td>
<td>

<p>Only used for objects <code>PVS.kNN</code> if <code>option=2</code>, <code>option=3</code> or <code>option=4</code>: sequence in which the  number of nearest neighbours <code>k.opt</code> is selected. The default is <code>object$knearest</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.knn.n</code></td>
<td>

<p>Only used for objects <code>PVS.kNN</code> if <code>option=2</code>, <code>option=3</code> or <code>option=4</code>: minumum value of the sequence in which the  number of nearest neighbours <code>k.opt</code> is selected (thus, this number must be smaller than the sample size). The default is <code>object$min.knn</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.knn.n</code></td>
<td>

<p>Only used for objects <code>PVS.kNN</code> if <code>option=2</code>, <code>option=3</code> or <code>option=4</code>: maximum value of the sequence in which the number of nearest neighbours <code>k.opt</code> is selected (thus, this number must be larger than <code>min.kNN</code> and smaller than the sample size). The default is <code>object$max.knn</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step.n</code></td>
<td>

<p>Only used for objects <code>PVS.kNN</code> if <code>option=2</code>, <code>option=3</code> or <code>option=4</code>: positive integer used to build the sequence of k-nearest neighbours in the following way: <code>min.knn, min.knn + step.n, min.knn + 2*step.n, min.knn + 3*step.n,...</code>. The default is  <code>object$step</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>To obtain the predictions of the response for <code>newdata.x</code> and <code>newdata.z</code>, the following options are provided:
</p>

<ul>
<li>
<p> If <code>option=1</code>, we maintain all the estimates (<code>k.opt</code> or <code>h.opt</code> and <code>beta.est</code>) to predict the functional nonparametric component of the model. As we use the estimates of the second step of the algorithm, only the <code>train.2</code> is used as training sample to predict.
Then, it should be noted that <code>k.opt</code> or <code>h.opt</code> may not be suitable to predict the functional nonparametric component of the model.
</p>
</li>
<li>
<p> If <code>option=2</code>, we maintain <code>beta.est</code>, while the tuning parameter (<code class="reqn">h</code> or <code class="reqn">k</code>) is selected again to predict the functional nonparametric component of the model. This selection is performed using the leave-one-out cross-validation (LOOCV) criterion in the associated functional nonparametric model and the complete training sample (i.e. <code>train=c(train.1,train.2)</code>), obtaining a global selection for <code class="reqn">h</code> or <code class="reqn">k</code>. As we use the entire training sample (not just a subsample of it), the sample size is modified and, as a consequence,  the parameters <code>knearest</code>, <code>min.knn</code>, <code>max.knn</code>, and <code>step</code> given to the function <code>IASSMR.kNN.fit</code> may need to be provided again to compute predictions. For that, we add the arguments <code>knearest.n</code>, <code>min.knn.n</code>, <code>max.knn.n</code> and <code>step.mn</code>. 
</p>
</li>
<li>
<p>  If <code>option=3</code>, we maintain only the indexes of the relevant variables selected by the IASSMR. We estimate again the linear coefficients  using <code>sfpl.kernel.fit</code> or <code>sfpl.kNN.fit</code>, respectively, without penalisation (setting <code>lambda.seq=0</code>) and using the entire training sample (<code>train=c(train.1,train.2)</code>). The method provides two predictions (and MSEPs):
</p>

<ul>
<li>
<p> a) The prediction associated with <code>option=1</code> for <code>sfpl.kernel</code> or <code>sfpl.kNN</code> class.
</p>
</li>
<li>
<p> b) The prediction associated with <code>option=2</code> for <code>sfpl.kernel</code> or <code>sfpl.kNN</code> class.
</p>
</li>
</ul>
<p>(see the documentation of the functions <code>predict.sfpl.kernel</code> and <code>predict.sfpl.kNN</code>)
</p>
</li>
<li>
<p> If <code>option=4</code> (an option only available for the class <code>PVS.kNN</code>) we maintain <code>beta.est</code>, while the tuning parameter <code class="reqn">k</code> is selected again to predict the functional nonparametric component of the model. This selection is performed using LOOCV criterion in the functional nonparametric model associated and the complete training sample (i.e. <code>train=c(train.1,train.2)</code>), obtaining a local selection for <code class="reqn">k</code>.
</p>
</li>
</ul>
<h3>Value</h3>

<p>The function returns the predicted values of the response (<code>y</code>) for <code>newdata.x</code> and <code>newdata.z</code>. If <code>!is.null(y.test)</code>, it also provides the mean squared error of prediction (<code>MSEP</code>) computed as <code>mean((y-y.test)^2)</code>.
If <code>option=3</code>, two sets of predictions (and two MSEPs) are provided, corresponding to the items a) and b) mentioned in the section <code>Details.</code>
If <code>is.null(newdata.x)</code> or <code>is.null(newdata.z)</code>, then the function returns the fitted values.
</p>


<h3>Author(s)</h3>

<p>German Aneiros Perez <a href="mailto:german.aneiros@udc.es">german.aneiros@udc.es</a> 
</p>
<p>Silvia Novo Diaz  <a href="mailto:snovo@est-econ.uc3m.es">snovo@est-econ.uc3m.es</a>
</p>


<h3>See Also</h3>

<p><code>PVS.kernel.fit</code>, <code>sfpl.kernel.fit</code> and <code>predict.sfpl.kernel</code> or <code>PVS.kNN.fit</code>,
<code>sfpl.kNN.fit</code> and <code>predict.sfpl.kNN</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Sugar)

y&lt;-Sugar$ash
x&lt;-Sugar$wave.290
z&lt;-Sugar$wave.240

#Outliers
index.y.25 &lt;- y &gt; 25
index.atip &lt;- index.y.25
(1:268)[index.atip]

#Dataset to model
x.sug &lt;- x[!index.atip,]
z.sug&lt;- z[!index.atip,]
y.sug &lt;- y[!index.atip]

train&lt;-1:216
test&lt;-217:266

#Fit
fit.kernel&lt;- PVS.kernel.fit(x=x.sug[train,],z=z.sug[train,], 
              y=y.sug[train],train.1=1:108,train.2=109:216,
              lambda.min.h=0.03,lambda.min.l=0.03,
              max.q.h=0.35, nknot=20,criterion="BIC",
              max.iter=5000)
fit.kNN&lt;- PVS.kNN.fit(x=x.sug[train,],z=z.sug[train,], y=y.sug[train],
            train.1=1:108,train.2=109:216,lambda.min.h=0.07, 
            lambda.min.l=0.07, nknot=20,criterion="BIC",
            max.iter=5000)

#Preditions
predict(fit.kernel,newdata.x=x.sug[test,],newdata.z=z.sug[test,],y.test=y.sug[test],option=2)
predict(fit.kNN,newdata.x=x.sug[test,],newdata.z=z.sug[test,],y.test=y.sug[test],option=2)

</code></pre>


</div>