<div class="container">

<table style="width: 100%;"><tr>
<td>fregre.gkam</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitting Functional Generalized Kernel Additive Models.</h2>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variables
<code class="reqn">(X^{1}(t_1),...,X^{q}(t_q))</code> and scalar response
<code class="reqn">Y</code> using backfitting algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fregre.gkam(
  formula,
  family = gaussian(),
  data,
  weights = rep(1, nobs),
  par.metric = NULL,
  par.np = NULL,
  offset = NULL,
  control = list(maxit = 100, epsilon = 0.001, trace = FALSE, inverse = "solve"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
procedure only considers functional covariates (not implemented for
non-functional covariates). The details of model specification are given
under <code>Details</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code>family</code> for details of family functions).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.metric</code></td>
<td>
<p>List of arguments by covariate to pass to the
<code>metric</code> function by covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.np</code></td>
<td>
<p>List of arguments to pass to the <code>fregre.np.cv</code> function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of parameters for controlling the fitting process, by
default: <code>maxit</code>, <code>epsilon</code>, <code>trace</code> and <code>inverse</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inverse</code></td>
<td>
<p>="svd" (by default) or ="solve" method.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The smooth functions <code class="reqn">f(.)</code> are estimated nonparametrically using a
iterative local scoring algorithm by applying Nadaraya-Watson weighted
kernel smoothers using <code>fregre.np.cv</code> in each step, see
Febrero-Bande and Gonzalez-Manteiga (2011) for more details.<br> 
Consider the fitted response <code class="reqn">\hat{Y}=g^{-1}(H_{Q}y)</code>,
where <code class="reqn">H_{Q}</code> is the weighted hat matrix.<br> Opsomer and Ruppert
(1997) solves a system of equations for fit the unknowns
<code class="reqn">f(\cdot)</code> computing the additive smoother matrix <code class="reqn">H_k</code>
such that <code class="reqn">\hat{f}_k (X^k)=H_{k}Y</code> and
<code class="reqn">H_Q=H_1+,\cdots,+H_q</code>. The additive model is fitted
as follows: </p>
<p style="text-align: center;"><code class="reqn">\hat{Y}=g^{-1}\Big(\sum_i^q
\hat{f_i}(X_i)\Big)</code>
</p>



<h3>Value</h3>


<ul>
<li> <p><code>result:</code> List of non-parametric estimation by covariate.
</p>
</li>
<li> <p><code>fitted.values:</code> Estimated scalar response. 
</p>
</li>
<li> <p><code>residuals:</code> <code>y</code> minus <code>fitted values</code>. 
</p>
</li>
<li> <p><code>effects:</code> The residual degrees of freedom. 
</p>
</li>
<li> <p><code>alpha:</code> Hat matrix. 
</p>
</li>
<li> <p><code>family:</code> Coefficient of determination. 
</p>
</li>
<li> <p><code>linear.predictors:</code> Residual variance.
</p>
</li>
<li> <p><code>deviance:</code> Scalar response. 
</p>
</li>
<li> <p><code>aic:</code> Functional explanatory data.
</p>
</li>
<li> <p><code>null.deviance:</code> Non functional explanatory data. 
</p>
</li>
<li> <p><code>iter</code>: Distance matrix between curves. 
</p>
</li>
<li> <p><code>w:</code> beta coefficient estimated
</p>
</li>
<li> <p><code>eqrank:</code> List that containing the variables in the model.
</p>
</li>
<li> <p><code>prior.weights:</code> Asymmetric kernel used. 
</p>
</li>
<li> <p><code>y:</code> Scalar response.
</p>
</li>
<li> <p><code>H:</code> Hat matrix, see Opsomer and Ruppert(1997) for more details.
</p>
</li>
<li> <p><code>converged:</code> conv.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Febrero-Bande M. and Gonzalez-Manteiga W. (2012).
<em>Generalized Additive Models for Functional Data</em>. TEST.
Springer-Velag.  <a href="https://doi.org/10.1007/s11749-012-0308-0">doi:10.1007/s11749-012-0308-0</a>
</p>
<p>Opsomer J.D. and Ruppert D.(1997). <em>Fitting a bivariate additive model
by local polynomial regression</em>.Annals of Statistics, <code>25</code>, 186-211.
</p>


<h3>See Also</h3>

<p>See Also as: <code>fregre.gsam</code>, <code>fregre.glm</code>
and <code>fregre.np.cv</code><br></p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
data(tecator)
ab=tecator$absorp.fdata[1:100]
ab2=fdata.deriv(ab,2)
yfat=tecator$y[1:100,"Fat"]

# Example 1: # Changing the argument par.np and family
yfat.cat=ifelse(yfat&lt;15,0,1)
xlist=list("df"=data.frame(yfat.cat),"ab"=ab,"ab2"=ab2)
f2&lt;-yfat.cat~ab+ab2

par.NP&lt;-list("ab"=list(Ker=AKer.norm,type.S="S.NW"),
"ab2"=list(Ker=AKer.norm,type.S="S.NW"))
res2=fregre.gkam(f2,family=binomial(),data=xlist,
par.np=par.NP)
res2

# Example 2: Changing the argument par.metric and family link
par.metric=list("ab"=list(metric=semimetric.deriv,nderiv=2,nbasis=15),
"ab2"=list("metric"=semimetric.basis))
res3=fregre.gkam(f2,family=binomial("probit"),data=xlist,
par.metric=par.metric,control=list(maxit=2,trace=FALSE))
summary(res3)

# Example 3: Gaussian family (by default)
# Only 1 iteration (by default maxit=100)
xlist=list("df"=data.frame(yfat),"ab"=ab,"ab2"=ab2)
f&lt;-yfat~ab+ab2
res=fregre.gkam(f,data=xlist,control=list(maxit=1,trace=FALSE))
res

## End(Not run)
</code></pre>


</div>