<div class="container">

<table style="width: 100%;"><tr>
<td>entropy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Shannon Entropy</h2>

<h3>Description</h3>

<p>KNN Shannon Entropy Estimators.</p>


<h3>Usage</h3>

<pre><code class="language-R">  entropy(X, k = 10, algorithm = c("kd_tree", "brute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>an input data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the maximum number of nearest neighbors to search. The default value is set to 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>nearest neighbor search algorithm.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a vector of length <code>k</code> for entropy estimates using <code>1:k</code> nearest neighbors, respectively.
</p>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:lishengqiao@yahoo.com">lishengqiao@yahoo.com</a></p>


<h3>References</h3>

<p>H. Singh, N. Misra, V. Hnizdo, A. Fedorowicz and E. Demchuk (2003). “Nearest neighbor
estimates of entropy”. <em>American Journal of Mathematical and Management Sciences</em>, <b>23</b>, 301-321.
</p>
<p>M.N. Goria, N.N.Leonenko, V.V. Mergel and P.L. Novi Inverardi (2005). 
“A new class of random vector entropy estimators and its applications in testing statistical hypotheses”.
<em>Journal of Nonparametric Statistics</em>, <b>17</b>:3, 277–297.
</p>
<p>R.M. Mnatsakanov, N. Misra, S. Li and E.J. Harner (2008). “K_n-nearest neighbor estimators of entropy”.
<em>Mathematical Methods of Statistics</em>, <b>17</b>:3, 261-277.
</p>


</div>