<div class="container">

<table style="width: 100%;"><tr>
<td>fusionbase</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fusion learning method for continuous responses
</h2>

<h3>Description</h3>

<p><code>fusionbase</code> conducts the group penalization to multiple linear models with a specified penalty value. <code>fusionbase.fit</code> can be used to search the best candidate model based on the pseudo Bayesian information criterion with a sequence of penalty values. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">fusionbase(x, y, lambda, N, p, m, beta=0.1, thresh=0.05, 
           maxiter=30, methods="scad",Complete=TRUE)

fusionbase.fit(x, y, lambda, N, p, m, beta=0.1, thresh=0.05, 
               maxiter=30, methods="scad", Complete=TRUE, depen ="IND", a=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>List. Listing matrices of the predictors from different platforms. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>List. A list of continuous responses vectors from different platforms following the same order as in <code>x</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>Numeric or vector. For <code>fusionbase</code>, lambda is a numeric value for the penalty; for <code>fusionbase.fit</code>, lambda is a vector with a list of penalty values. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>

<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each data set. If a vector is provided, then the elements are the sample sizes for all the platforms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>

<p>Numeric. The number of predictors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>

<p>Numeric. The number of platforms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>

<p>Numeric or Matrix. An initial value for the estimated parameters with dimensions nvars x nplatforms. The defaul value is 0.1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thresh</code></td>
<td>

<p>Numeric. The stopping criteria. The default value is 0.05.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>

<p>Numeric. Maximum number of iterations. The default value is 30.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>methods</code></td>
<td>

<p>Character ("lass" or "scad"). <code>lass</code>: LASSO; <code>scad</code>: SCAD.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Complete</code></td>
<td>

<p>Logic input. If <code>Complete == TRUE</code>, the predictors <code class="reqn">M_1</code>,...,<code class="reqn">M_p</code> are measured in all platforms. If <code>Compelte == FALSE</code>, in some platforms, not all of the predictors <code class="reqn">\{M_1,M_2,...,M_p\}</code> are measured. The values of the corresponding estimated coefficients for the missing predictors will be <code>NA</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>depen</code></td>
<td>

<p>Character. Input only for function <code>fusionbase.fit</code>. "IND" means the observations across different platforms are independent; "CORR" means the observations are correlated, and the sample sizes should be equal for different platforms. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>

<p>Numeric. Input only for function <code>fusionbase.fit</code>. The free multiplicative constant used in <code class="reqn">\gamma_n</code>. The default value is 1.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The basic fusion learning function to learn from multiple linear models with continuous responses. More details regarding the model assumptions and the algorithm can be found in <code>FusionLearn</code>.
</p>


<h3>Value</h3>

<p><code>fusionbase</code> returns a list that has components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>

<p>A matrix (nvars x nplatforms) containing estimated coefficients of each linear model. If some data sets do not have the complete set of predictors, the corresponding coefficients are output as <code>NA</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>Penalty function LASSO or SCAD.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>

<p>The numeric value shows the difference in the estimates between the successive updates upon convergence. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iteration</code></td>
<td>

<p>The numeric value shows the number of iterations upon convergence.
</p>
</td>
</tr>
</table>
<p><code>fusionbase.fit</code> provides the results in a table:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>The sequence of penalty values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BIC</code></td>
<td>

<p>The pseudolikelihood Bayesian information criterion evaluated at the sequence of the penalty values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>-2Loglkh</code></td>
<td>

<p>Minus twice the pseudo loglikelihood of the chosen model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Est_df</code></td>
<td>

<p>The estimated degrees of freedom quantifying the model complexity.
</p>
</td>
</tr>
</table>
<p><code>fusionbase.fit</code> also returns a model selection plot showing the results above. 
</p>


<h3>Note</h3>

<p>The range of the penalty values should be carefully chosen. For some penalty values, the resulting models may have singular information matrix or the fitting of the glm cannot converge.
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong, and Raymond J. Carroll
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>Examples</h3>

<pre><code class="language-R">##analysis of the stock index data
#Responses contain indices "VIX","GSPC", and "DJI" 
y &lt;- list(stockindexVIX[,1],stockindexGSPC[,1],stockindexDJI[,1]) 

#Predictors include 46 stocks
x &lt;- list(stockindexVIX[,2:47],stockindexGSPC[,2:47],stockindexDJI[,2:47])  

##Implementing the model selection algorithm based on the psuedolikelihood 
##information criteria  
model &lt;- fusionbase.fit(x,y,seq(0.03,5,length.out = 10),232,46,3,depen="CORR")
lambda &lt;- model[which.min(model[,2]),1]
result &lt;- fusionbase(x,y,lambda,232,46,3)

##Identify the significant predictors for the three indices
id &lt;- which(result$beta[,1]!=0)+1
colnames(stockindexVIX)[id]
</code></pre>


</div>