<div class="container">

<table style="width: 100%;"><tr>
<td>RegressionTestsInterface</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Regression Tests</h2>

<h3>Description</h3>

<p>A collection and description of functions 
to test linear regression  models, including
tests for higher serial correlations, for 
heteroskedasticity, for autocorrelations 
of disturbances, for linearity, and functional 
relations.
<br></p>
<p>The methods are:
</p>

<table>
<tr>
<td style="text-align: left;">
    <code>"bg"</code> </td>
<td style="text-align: left;"> Breusch--Godfrey test for higher order serial correlation, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"bp"</code> </td>
<td style="text-align: left;"> Breusch--Pagan test for heteroskedasticity, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"dw"</code> </td>
<td style="text-align: left;"> Durbin--Watson test for autocorrelation of disturbances, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"gq"</code> </td>
<td style="text-align: left;"> Goldfeld--Quandt test for heteroskedasticity, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"harv"</code> </td>
<td style="text-align: left;"> Harvey--Collier test for linearity, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"hmc"</code> </td>
<td style="text-align: left;"> Harrison--McCabe test for heteroskedasticity, </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"rain"</code> </td>
<td style="text-align: left;"> Rainbow test for linearity, and </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"reset"</code> </td>
<td style="text-align: left;"> Ramsey's RESET test for functional relation. </td>
</tr>
</table>
<p>There is nothing new, it's just a wrapper to the underlying test
functions from R's contributed package <code>lmtest</code>. The functions
are available as "Builtin" functions. Nevertheless, the user can 
still install and use the original functions from <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>'s <code>lmtest</code> 
package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lmTest(formula, method = c("bg", "bp", "dw", "gq", "harv", "hmc", 
    "rain", "reset"), data = list(), ...)
    
bgTest(formula, order = 1, type = c("Chisq", "F"), data = list())
bpTest(formula, varformula = NULL, studentize = TRUE, data = list())
dwTest(formula, alternative = c("greater", "two.sided", "less"),
    iterations = 15, exact = NULL, tol = 1e-10, data = list())
gqTest(formula, point=0.5, order.by = NULL, data = list())
harvTest(formula, order.by = NULL, data = list())
hmcTest(formula, point = 0.5, order.by = NULL, simulate.p = TRUE, 
    nsim = 1000, plot = FALSE, data = list()) 
rainTest(formula, fraction = 0.5, order.by = NULL, center = NULL, 
    data = list())
resetTest(formula, power = 2:3, type = c("fitted", "regressor", "princomp"), 
    data = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>

<p>[dwTest] - <br>
a character string specifying the alternative hypothesis, either
<code>"greater"</code>, <code>"two.sided"</code>, or <code>"less"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>

<p>[rainTest] - <br>
a numeric value. If center is smaller than <code>1</code> it is 
interpreted as percentages of data, i.e. the subset is chosen 
that <code>n*fraction</code> observations are around observation 
number <code>n*center</code>. If <code>center</code> is greater than 
<code>1</code> it is interpreted to be the index of the center of 
the subset. By default center is <code>0.5</code>. If the Mahalanobis 
distance is chosen center is taken to be the mean regressor, 
but can be specified to be a k-dimensional vector if k is the 
number of regressors and should be in the range of the 
respective regressors. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which 
<code>lmTest</code> and the other tests are called from.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exact</code></td>
<td>

<p>[dwTest] - <br>
a logical flag. If set to <code>FALSE</code> a normal approximation 
will be used to compute the p value, if <code>TRUE</code> the "pan" 
algorithm is used. The default is to use "pan" if the sample size 
is <code>&lt; 100</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>

<p>a symbolic description for the linear model to be tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fraction</code></td>
<td>

<p>[rainTest] - <br>
a numeric value, by default 0.5. The percentage of observations 
in the subset is determined by <code>fraction*n</code> if <code>n</code> 
is the number of observations in the model. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterations</code></td>
<td>

<p>[dwTest] - <br>
an integer specifying the number of iterations when calculating
the p-value with the "pan" algorithm. By default 15.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>the test method which should be applied.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>

<p>[hmcTest] - <br>
an integer value. Determines how many runs are used to 
simulate the p value, by default 1000.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>
 
<p>[bgTest] - <br>
an integer. The maximal order of serial correlation to be 
tested. By default 1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order.by</code></td>
<td>

<p>[gqTest][harvTest] - <br>
a formula. A formula with a single explanatory variable like 
<code>~ x</code>. Then the observations in the model are ordered by 
the size of <code>x</code>. If set to <code>NULL</code>, the default, the 
observations are assumed to be ordered (e.g. a time series). <br>
[rainTest] - <br>
either a formula or a string. A formula with a single explanatory 
variable like <code>~ x</code>. The observations in the model are 
ordered by the size of <code>x</code>. If set to <code>NULL</code>, the default, 
the observations are assumed to be ordered (e.g. a time series). 
If set to <code>"mahalanobis"</code> then the observations are ordered 
by their Mahalanobis distance of the data. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>

<p>[hmcTest] - <br>
a logical flag. If <code>TRUE</code> the test statistic for all  
possible breakpoints is plotted, the default is <code>FALSE</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>point</code></td>
<td>

<p>[gqTest][hmcTest] - <br>
a numeric value. If point is smaller than <code>1</code> it is 
interpreted as percentages of data, i.e. <code>n*point</code> is 
taken to be the (potential) breakpoint in the variances, if 
<code>n</code> is the number of observations in the model. If 
<code>point</code> is greater than <code>1</code> it is interpreted to 
be the index of the breakpoint. By default <code>0.5</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power</code></td>
<td>

<p>[resetTest] - <br>
integers, by default <code>2:3</code>. A vector of positive integers 
indicating the powers of the variables that should be included. 
By default it is tested for a quadratic or cubic influence of 
the fitted response. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simulate.p</code></td>
<td>

<p>[hmcTest] - <br>
a logical. If <code>TRUE</code>, the default, a p-value will be 
assessed by simulation, otherwise the p-value is <code>NA</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>studentize</code></td>
<td>

<p>[bpTest] - <br> 
a logical value. If set to <code>TRUE</code> 
Koenker's studentized version of the test statistic will 
be used. By default set to <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>[dwTest] - <br>
the tolerance value. Eigenvalues computed have to be greater than 
<code>tol=1e-10</code> to be treated as non-zero. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>

<p>[bgTest] - <br>
the type of test statistic to be returned. Either <code>"Chisq"</code> 
for the Chi-squared test statistic or <code>"F"</code> for the F test 
statistic. <br>
[resetTest] - <br>
a string indicating whether powers of the <code>"fitted"</code> 
response, the <code>"regressor"</code> variables (factors are left 
out) or the first principal component, <code>"princomp"</code>, of 
the regressor matrix should be included in the extended model. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varformula</code></td>
<td>

<p>[bpTest] - <br>
a formula describing only the potential explanatory variables 
for the variance, no dependent variable needed. By default the 
same explanatory variables are taken as in the main regression 
model. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>[regTest] - <br>
additional arguments passed to the underlying lm test. Some of 
the tests can specify additional optional arguments like for
alternative hypothesis, the type of test statistic to be returned,
or others. All the optional arguments have default settings. 
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>bg â€“ Breusch Godfrey Test:</b>
<br><br>  
Under <code class="reqn">H_0</code> the test statistic is asymptotically Chi-squared 
with degrees of freedom as given in <code>parameter</code>.
If <code>type</code> is set to <code>"F"</code> the function returns
the exact F statistic which, under <code class="reqn">H_0</code>, follows an <code class="reqn">F</code>
distribution with degrees of freedom as given in <code>parameter</code>.
The starting values for the lagged residuals in the supplementary
regression are chosen to be 0.<br><code>[lmtest:bgtest]</code>
<br></p>
<p><b>bp â€“ Breusch Pagan Test:</b>
<br><br>
The Breuschâ€“Pagan test fits a linear regression model to the 
residuals of a linear regression model (by default the same 
explanatory variables are taken as in the main regression
model) and rejects if too much of the variance
is explained by the additional explanatory variables.
Under <code class="reqn">H_0</code> the test statistic of the Breusch-Pagan test 
follows a chi-squared distribution with <code>parameter</code> 
(the number of regressors without the constant in the model) 
degrees of freedom.<br><code>[lmtest:bptest]</code>
<br></p>
<p><b>dw â€“ Durbin Watson Test:</b>
<br><br>
The Durbinâ€“Watson test has the null hypothesis that the autocorrelation
of the disturbances is 0; it can be tested against the alternative 
that it is greater than, not equal to, or less than 0 respectively. 
This can be specified by the <code>alternative</code> argument.
The null distribution of the Durbin-Watson test statistic is a linear
combination of chi-squared distributions. The p value is computed using a
Fortran version of the Applied Statistics Algorithm AS 153 by Farebrother
(1980, 1984). This algorithm is called "pan" or "gradsol". For large sample
sizes the algorithm might fail to compute the p value; in that case a 
warning is printed and an approximate p value will be given; this p 
value is computed using a normal approximation with mean and variance 
of the Durbin-Watson test statistic.<br><code>[lmtest:dwtest]</code>
<br></p>
<p><b>gq â€“ Goldfeld Quandt Test:</b>
<br><br>
The Goldfeldâ€“Quandt test compares the variances of two submodels
divided by a specified breakpoint and rejects if the variances differ.
Under <code class="reqn">H_0</code> the test statistic of the Goldfeld-Quandt test 
follows an F distribution with the degrees of freedom as given in 
<code>parameter</code>.<br><code>[lmtest:gqtest]</code>
<br></p>
<p><b>harv - Harvey Collier Test:</b>
<br><br>
The Harvey-Collier test performs a t-test (with <code>parameter</code> 
degrees of freedom) on the recursive residuals. If the true relationship 
is not linear but convex or concave the mean of the recursive residuals 
should differ from 0 significantly.<br><code>[lmtest:harvtest]</code>
<br></p>
<p><b>hmc â€“ Harrison McCabe Test:</b>
<br><br>  
The Harrisonâ€“McCabe test statistic is the fraction of the residual 
sum of squares that relates to the fraction of the data before the 
breakpoint. Under <code class="reqn">H_0</code> the test statistic should be close to 
the size of this fraction, e.g. in the default case close to 0.5. 
The null hypothesis is reject if the statistic is too small.<br><code>[lmtest:hmctest]</code>
<br></p>
<p><b>rain â€“ Rainbow Test:</b>
<br><br>  
The basic idea of the Rainbow test is that even if the true 
relationship is non-linear, a good linear fit can be achieved 
on a subsample in the "middle" of the data. The null hypothesis 
is rejected whenever the overall fit is significantly inferior 
to the fit of the subsample. The test statistic under <code class="reqn">H_0</code> 
follows an F distribution with <code>parameter</code> degrees of 
freedom.<br><code>[lmtest:raintest]</code>
<br></p>
<p><b>reset â€“ Ramsey's RESET Test</b>
<br><br>  
RESET test is popular means of diagnostic for correctness of 
functional form. The basic assumption is that under the alternative, 
the model can be written by the regression
<code class="reqn"> y = X\beta + Z\gamma + u</code>.
<code>Z</code> is generated by taking powers either of the fitted response, 
the regressor variables or the first principal component of <code>X</code>. 
A standard F-Test is then applied to determine whether these additional 
variables have significant influence. The test statistic under 
<code class="reqn">H_0</code> follows an F distribution with <code>parameter</code> degrees 
of freedom.<br><code>[lmtest:reset]</code>
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic</code></td>
<td>

<p>the value of the test statistic.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter</code></td>
<td>

<p>the lag order.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>

<p>the p-value of the test.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>a character string indicating what type of test was
performed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>

<p>a character string giving the name of the data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>

<p>a character string describing the alternative
hypothesis.
</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The underlying <code>lmtest</code> package comes wit a lot of helpful
examples. We highly recommend to install the <code>lmtest</code> package
and to study the examples given therein.
</p>


<h3>Author(s)</h3>

<p>Achim Zeileis and Torsten Hothorn for the <code>lmtest</code> package, <br>
Diethelm Wuertz for the Rmetrics <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>-port.
</p>


<h3>References</h3>

<p>Breusch, T.S. (1979);
<em>Testing for Autocorrelation in Dynamic Linear Models</em>, 
Australian Economic Papers 17, 334â€“355.
</p>
<p>Breusch T.S. and Pagan A.R. (1979);
<em>A Simple Test for Heteroscedasticity and Random 
Coefficient Variation</em>,
Econometrica 47, 1287â€“1294
</p>
<p>Durbin J. and Watson G.S. (1950);
<em>Testing for Serial Correlation in Least Squares Regression I</em>,
Biometrika 37, 409â€“428.
</p>
<p>Durbin J. and Watson G.S. (1951);
<em>Testing for Serial Correlation in Least Squares Regression II</em>,
Biometrika 38, 159â€“178.
</p>
<p>Durbin J. and Watson G.S. (1971);
<em>Testing for Serial Correlation in Least Squares Regression III</em>,
Biometrika 58, 1â€“19.
</p>
<p>Farebrother R.W. (1980);
<em>Pan's Procedure for the Tail Probabilities of the
Durbin-Watson Statistic</em>,
Applied Statistics 29, 224â€“227.
</p>
<p>Farebrother R.W. (1984);
<em>The Distribution of a Linear Combination of
<code class="reqn">\chi^2</code> Random Variables</em>, 
Applied Statistics 33, 366â€“369.
</p>
<p>Godfrey, L.G. (1978);
<em>Testing Against General Autoregressive and
Moving Average Error Models when the Regressors Include Lagged
Dependent Variables</em>, 
Econometrica 46, 1293â€“1302.
</p>
<p>Goldfeld S.M. and Quandt R.E. (1965);
<em>Some Tests for Homoskedasticity</em>
Journal of the American Statistical Association 60, 539â€“547.
</p>
<p>Harrison M.J. and McCabe B.P.M. (1979);
<em>A Test for Heteroscedasticity based on Ordinary Least 
Squares Residuals</em>
Journal of the American Statistical Association 74, 494â€“499.
</p>
<p>Harvey A. and Collier P. (1977);
<em>Testing for Functional Misspecification in Regression 
Analysis</em>,
Journal of Econometrics 6, 103â€“119.
</p>
<p>Johnston, J. (1984); 
<em>Econometric Methods</em>, 
Third Edition, McGraw Hill Inc.
</p>
<p>Kraemer W. and Sonnberger H. (1986);
<em>The Linear Regression Model under Test</em>, 
Heidelberg: Physica.
</p>
<p>Racine J. and Hyndman R. (2002);
<em>Using R To Teach Econometrics</em>,
Journal of Applied Econometrics 17, 175â€“189.
</p>
<p>Ramsey J.B. (1969);
<em>Tests for Specification Error in Classical Linear Least 
Squares Regression Analysis</em>,
Journal of the Royal Statistical Society, Series B 31, 350â€“371.
</p>
<p>Utts J.M. (1982);
<em>The Rainbow Test for Lack of Fit in Regression</em>,
Communications in Statistics - Theory and Methods 11, 1801â€“1815.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## bg | dw -
   # Generate a Stationary and an AR(1) Series:
   x = rep(c(1, -1), 50)
   y1 = 1 + x + rnorm(100)
   # Perform Breusch-Godfrey Test for 1st order serial correlation:
   lmTest(y1 ~ x, "bg")
   # ... or for fourth order serial correlation:
   lmTest(y1 ~ x, "bg", order = 4)    
   # Compare with Durbin-Watson Test Results:
   lmTest(y1 ~ x, "dw")
   y2 = filter(y1, 0.5, method = "recursive")
   lmTest(y2 ~ x, "bg") 
   
## bp -
   # Generate a Regressor:
   x = rep(c(-1, 1), 50)
   # Generate heteroskedastic and homoskedastic Disturbances
   err1 = rnorm(100, sd = rep(c(1, 2), 50))
   err2 = rnorm(100)
   # Generate a Linear Relationship:
   y1 = 1 + x + err1
   y2 = 1 + x + err2
   # Perform Breusch-Pagan Test
   bp = lmTest(y1 ~ x, "bp")
   bp
   # Calculate Critical Value for 0.05 Level
   qchisq(0.95, bp$parameter)
   lmTest(y2 ~ x, "bp")
   
## dw -
   # Generate two AR(1) Error Terms 
   # with parameter rho = 0 (white noise) 
   # and rho = 0.9 respectively
   err1 = rnorm(100)
   # Generate Regressor and Dependent Variable
   x = rep(c(-1,1), 50)
   y1 = 1 + x + err1
   # Perform Durbin-Watson Test:
   lmTest(y1 ~ x, "dw")
   err2 = filter(err1, 0.9, method = "recursive")
   y2 = 1 + x + err2
   lmTest(y2 ~ x, "dw")
   
## gq -
   # Generate a Regressor:
   x = rep(c(-1, 1), 50)
   # Generate Heteroskedastic and Homoskedastic Disturbances:
   err1 = c(rnorm(50, sd = 1), rnorm(50, sd = 2))
   err2 = rnorm(100)
   # Generate a Linear Relationship:
   y1 = 1 + x + err1
   y2 = 1 + x + err2
   # Perform Goldfeld-Quandt Test:
   lmTest(y1 ~ x, "gq")
   lmTest(y2 ~ x, "gq")
   
## harv -
   # Generate a Regressor and Dependent Variable:
   x = 1:50
   y1 = 1 + x + rnorm(50)
   y2 = y1 + 0.3*x^2
   # Perform Harvey-Collier Test:
   harv = lmTest(y1 ~ x, "harv")
   harv
   # Calculate Critical Value vor 0.05 level:
   qt(0.95, harv$parameter)
   lmTest(y2 ~ x, "harv")
   
## hmc -
   # Generate a Regressor:
   x = rep(c(-1, 1), 50)
   # Generate Heteroskedastic and Homoskedastic Disturbances:
   err1 = c(rnorm(50, sd = 1), rnorm(50, sd = 2))
   err2 = rnorm(100)
   # Generate a Linear Relationship:
   y1 = 1 + x + err1
   y2 = 1 + x + err2
   # Perform Harrison-McCabe Test:
   lmTest(y1 ~ x, "hmc")
   lmTest(y2 ~ x, "hmc")
   
## rain -
   # Generate Series:
   x = c(1:30)
   y = x^2 + rnorm(30, 0, 2)
   # Perform rainbow Test
   rain = lmTest(y ~ x, "rain")
   rain
   # Compute Critical Value:
   qf(0.95, rain$parameter[1], rain$parameter[2]) 
   
## reset -
   # Generate Series:
   x = c(1:30)
   y1 = 1 + x + x^2 + rnorm(30)
   y2 = 1 + x + rnorm(30)
   # Perform RESET Test:
   lmTest(y1 ~ x , "reset", power = 2, type = "regressor")
   lmTest(y2 ~ x , "reset", power = 2, type = "regressor")          
</code></pre>


</div>